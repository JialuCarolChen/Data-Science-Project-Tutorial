{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dsk4FUnOUx3s"
   },
   "source": [
    "## Authenticate and create PyDrive client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_FCt_RtAnpE"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# PyDrive reference:\n",
    "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaAbndQYVTKB"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oknGSWjHNCmO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "A2siYFZuM2JJ",
    "outputId": "d0624a1b-5aba-41fc-e179-a08ff52e531a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: training_desc.csv, id: 1kSoeoaK_TsTHnhSGPXOLNy43jd20G8bH\n",
      "title: training_data.csv, id: 12-B9GpferXatOB4ACo7GanQ2iBt5O-66\n",
      "title: test_data.csv, id: 1y_YySFyibYYwQtJr6v7Qf81FqULwK7Fk\n",
      "title: training_labels.csv, id: 1cqErOBjBB91P_xrt4TKuZ91OfTLoUYmx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_list = drive.ListFile({'q': \"'1j8oG_vCmum9YuVWP8LdbSkfj-lfi-AZ0' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGOTPZQWWlf8"
   },
   "source": [
    "### Pulling data into Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "vo17S6sITJfa"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "training_data_downloaded = drive.CreateFile({'id': '12-B9GpferXatOB4ACo7GanQ2iBt5O-66'})\n",
    "training_data_downloaded.GetContentFile('training_data.csv')\n",
    "\n",
    "#training_desc_downloaded = drive.CreateFile({'id': '1kSoeoaK_TsTHnhSGPXOLNy43jd20G8bH'})\n",
    "#training_desc_downloaded.GetContentFile('training_desc.csv')\n",
    "\n",
    "training_labels_downloaded = drive.CreateFile({'id': '1cqErOBjBB91P_xrt4TKuZ91OfTLoUYmx'})\n",
    "training_labels_downloaded.GetContentFile('training_labels.csv')\n",
    "\n",
    "#test_data_downloaded = drive.CreateFile({'id': '1y_YySFyibYYwQtJr6v7Qf81FqULwK7Fk'})\n",
    "#test_data_downloaded.GetContentFile('test_data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhI6TXRtWsl7"
   },
   "source": [
    "### Load data files\n",
    "(example:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "saVLVnGvT59I"
   },
   "outputs": [],
   "source": [
    "def data_loader():\n",
    "  traindata = pd.read_csv('training_data.csv', header=None).sort_values([0])\n",
    "  # df_desc = pd.read_csv('training_desc.csv')\n",
    "  trainlabel = pd.read_csv('training_labels.csv', header=None).sort_values([0])\n",
    "  # df_test = pd.read_csv('test_data.csv')\n",
    "  #@title Default title text\n",
    "  variable_name = 0 #@param {type:\"raw\"}\n",
    "  traindata = traindata.drop(0, 1)\n",
    "  trainlabel = trainlabel.drop(0, 1)\n",
    "\n",
    "  traindata = csr_matrix(traindata.values)\n",
    "  labels, trainlabel = np.unique(trainlabel, return_inverse = True)\n",
    "  return traindata, trainlabel, labels\n",
    "\n",
    "traindata, trainlabel, labels = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_9yMelvf_GK"
   },
   "source": [
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "gLTZP81spVJe"
   },
   "outputs": [],
   "source": [
    "class OneHotEncoding(object):\n",
    "    \n",
    "    def transform(Y):\n",
    "        labels = []\n",
    "        numclass = len(np.unique(Y))\n",
    "        for value in Y:\n",
    "            classes = [0 for _ in range(numclass)]\n",
    "            classes[value] = 1\n",
    "            labels.append(classes)\n",
    "        return np.array(labels)\n",
    "    \n",
    "    def inverse_transform(Y):\n",
    "        return np.argmax(Y, axis = 1)\n",
    "      \n",
    "#Y = OneHotEncoding.transform(trainlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WP6x1GfHgrX1"
   },
   "source": [
    "This project aims to experiment different machine learning methodologies to solve a text classification problem. Given a fixed set of classes and a training set of labelled documents, we seek to learn a classifier that maps documents to classes. The documents are represented by some high dimensional space, where each dimension represents a word and the TF-IDF value in that column is a numerical statistic to estimate the importance of that word to a document with respect to the collection of documents (Schütze, & Raghavan, 2008). In order to build the classifier, the training documents are split into a training and a validation set. The training set provides typical examples for the classifier to learn, while the validation set is used to tune the classifier. The goal of the classifier is to achieve high accuracy on a testing set of documents. This is a supervised learning process because the training documents are served as a \"supervisor\" to direct the modelling. Two supervised learning methodologies have been chosen to build the classifier: multinominal naïve bayes and multinomial logistic regression. We are interested in exploring the characteristic of these types of classifiers and to compare their performance. Additionally, we are also interested in studying other methods to leverage the performance of our classifiers. One method is to build an ensemble model on top of the multinominal naïve bayes classifiers and the multinomial logistic regression classifiers. Another is to experiment with some feature reduction techniques to improve learning efficiency and avoid overfitting.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8mv5DpMabae"
   },
   "source": [
    "## 1. Multinomial Naïve Bayes Classifier\n",
    "Naïve Bayes classifier has been a popular method to solve text classification problem since the early 1960s (Russell, 2016). It is a probabilistic learning model based on Bayes' theorem. In Bayes' theorem, the probability of an event A occurring under the condition of event B is determined by three elements: some prior knowledge about event A, the likelihood of event B occurring under the condition of event A occurring, and the probability of event B occurring (Lewis, 1998). Here is the formula: \n",
    "\n",
    "**P(A|B) = (P(B|A)XP(A)) / P(B)**\n",
    "\n",
    "In a text classification problem, our goal is to find the class c that a document d has the highest probability belonging to. The conditional probability of a document d belonging to a class c can be denoted as P(c|d). Given a document d and a set of possible classes c=c1, c2, …, ck, the Multinomial Naïve Bayes classifier returns the class that has the highest P(c|d) as the prediction. P(c|d) is calculated following the Bayes' theorem:\n",
    "\n",
    "**MNB_Prediction = argmax_c{P(c|d)}**\n",
    "\n",
    "**= argmax_c{P(d|c)XP(c) / P(d)}** --following Bayes' Theorem\n",
    "\n",
    "**= argmax_c{P(d|c)XP(c)}** --P(d) can be ignored because it is not related to c\n",
    "\n",
    "In the above formula, P(d|c) is the likelihood of a document d occurring in class c. Multinomial Naïve Bayes classifier makes some 'naive' assumption and simplification to calculate this probability. It treats the distribution of words in the documents as a multinomial, and it assumes that the occurrences of words are independent from each other (Rennie et al., 2003). Under this assumption, P(d|c) can be calculated from the joint probability of P(w1|c), P(w2|c), …, P(wn|c), where w1, w2, …, wn are all unique words in the documents:\n",
    "\n",
    "**P(d|c) = P(w1|c)XP(w2|c)…XP(wn|c)**\n",
    "\n",
    "Now, we have MNB_Prediction = argmax_c{P(c)*P(w1|c)*P(w2|c)…*P(wn|c)}.  \n",
    "From this equation, there is an obvious problem to be observed. In practice, we usually have a very large space of unique words. This leads to multiplying lots of conditional probabilities together and results in a very small value with floating point overflow. According to Schütze, Manning, and Raghavan (2008), log transformation can be applied to solve this problem:\n",
    "\n",
    "**MNB_Prediction = argmax_c{logP(c) + logP(w1|c) + logP(w2|c)…+ logP(wn|c)}**\n",
    "\n",
    "Given a training set of documents d and their labelling classes, the multinomial naïve bayes classifier will learn the prior knowledge of each classes P(c), where c=c1, c2, …, ck; and the likelihood P(w|c) for all unique words in the word space w=w1, w2, …, wn. P(c) can be easily calculated by counting the occurrence of the training documents in class c, divided by the total occurrence of training documents: \n",
    "\n",
    "**P(c) = Count(training documents in class c) / Count(all training documents)**\n",
    "\n",
    "P(wi|c) can be calculated by counting the occurrence of word wi in training documents of class c, divided by the total occurrence of words in the training documents of class c. In this project, the word occurrence is represented by the tf-idf value. Let T_wi_c denotes the sum of the tf-idf value of word w in documents of class c, we can calculate P(w|c) as follows:\n",
    "\n",
    "**P(wi|c) = T_wi_c / (T_w1_c + T_w2_c + … + T_wn_c) = T_wi_c / Sum(T_w_c)**\n",
    "\n",
    "However, in practice, not every unique word appears in all of the classes, which means that we will have P(w|c) equals to 0 for unseen words in class c. In this case, logP(c) + logP(w1|c) + logP(w2|c)…+ logP(wn|c) will always be negative infinity for all classes c. Laplacian smoothing can be used to solve this problem by shifting some small positive probability to unseen words (Schütze, Manning, & Raghavan, 2008). Let alpha be a parameter to control how much positive probability we want to shift, |W| denotes the number of unique words in the word space, we transform the formula with laplacian smoothing as follow: \n",
    "\n",
    "**P(wi|c) = (T_wi_c + alpha) / (Sum(T_w_c) + |W|)**\n",
    "\n",
    "After learning the prior knowledge P(c) and the likelihood P(wi|c) from the training documents, the multinomial naïve bayes classifier can predict the best class for a new document d_new (from the validation or testing data) based on the following calculation:\n",
    "\n",
    "**MNB_Prediction = argmax_c{logP(c) + f1XlogP(w1|c) + f2XlogP(w2|c)…+ fnXlogP(wn|c)}**\n",
    "\n",
    "where f1, f2, …, fn denotes the word frequency of w1, w2, …, wn in d_new, which are the tf-idf values in this project. \n",
    "\n",
    "## 2. Multinomial Logistic Regression Classifier\n",
    "\n",
    "Multinomial Logistic regression, also known as softmax regression and maximum entropy classifier, is a supervised learning method that can be used in multiclass classification problems. It is very similar to logistic regression except for the fact that the outcomes of the model, which can be seen as a categorical dependent variable, is multivalued instead of binary (Vryniotis, 2013). Statistically speaking, multinomial logistic regression is a predictive analysis that predicts the dependent categorical variable from a set of independent variables (Vryniotis, 2013). The model learns the relationship between the dependent variable and the independent variables from some sample data. In a text classification problem, a document can be seen as a data sample, the dependent variable is the class that a document belonging to, and the independent variables are the occurrence of words in the document word space. \n",
    "Like logistic regression, in order to predict the outcomes from the independent variables, the model assumes there is a linear relationship in between the outcome and the independent variables (Vryniotis, 2013). Let c denotes the possible classes that a document can belong to, d denotes a document, f(c, d) denotes the probability of a document d belonging to class c. In the text classification problem, multinomial logistic regression assumes f(c, d) has a linear relationship with the occurrence of the words w1, w2, w3, …, wn:\n",
    "\n",
    "**f(c, d) = b0,c + b1,c X w1,d + b2,c X w2,d +…+ bn,c X wn,d**\n",
    "\n",
    "As we can see from the above equation, so far f(c, d) is not a legal probability. The sum b0,c + b1,c X w1,d' + b2,c X w2,d' +…+ bn,c X wn,d' produce values from negative infinity to positive infinity instead 0 to 1. According to Martin(2009), this can be easily solved by wrapping up the sum with a softmax function:\n",
    "\n",
    "**f(c, d) = exp(Bc∙Xd) / (Sum(exp(Bc'∙Xd)))**\n",
    "\n",
    "where Bc = b0,c, b1,c, b2,c, …+ bn, c is a set of coefficients to parameterize the relationship, Xd is a vector of wj,d, and wj,d is the tf-idf value of word j in a given document d. \n",
    "\n",
    "Bc is unique for each class and they are learnt by the model from some training data. After Bc is learnt, they are used to predict the best class for a given document d'\n",
    "\n",
    "**MLR_Prediction = argmax_c(f(c, d'))** \n",
    "\n",
    "For our specific multinomial logistic regression, we use mini-batch stochastic gradient descent to optimise our weights, updating them to minimise our cost function output. The cost function in multionomial Logistic Regression is categorical cross entropy:\n",
    "\n",
    "**cost = -sum(y*log(p))**\n",
    "\n",
    "where y is the true label value and p is the prediction probability.\n",
    "\n",
    "One advantage of multinomial logistic regression classifier over multinomial naïve bayes classifiers is that the model does not need to assume statistical independence between the independent variables, which are the occurrence of words in the text classification problem (Martin, 2009). Preserving the dependent relationship between words can potentially give us a better prediction result. However, multinomial logistic regression requires a much larger timeframe to be trained compared to multinomial naïve bayes classifier. This is due to its iterative nature to estimate the parameters of the model (Vryniotis, 2013).\n",
    "\n",
    "## 3. Ensemble Learning\n",
    "\n",
    "Ensemble learning is a technique that combines individually trained base models into one predictive model in order to improve prediction result (Opitz, 1999). Both empirical and theoretical research has proved that the combined model, which is usually called an ensemble, generally outperforms any of the individual base models making up the ensemble (Opitz, 1999). \n",
    "In this project, we first designed a simple cross validation ensemble model. In cross validation, the training dataset is split into k folds with one of them as the validation fold, and the other k-1 folds as the training folds. We build naïve bayes and logistic regression classifiers respectively at each training folds and average their prediction results. It is hypothesised that this ensemble model will give better prediction results due to following reasons: the stronger base classifier can pull up the performance of the weaker base classifier; avoid learning bias from a specific subset of data; instead of using sampling method to obtain data subsets, using the cross-validation folds can ensure the model makes the most use of the training data.  \n",
    "Additionally, we also considered a widely known ensemble method to leverage our naïve bayes classifier and logistic regression classifier: bagging. Bagging reduces the variance and bias of the prediction by averaging the results returned from multiple base models (Smolyakov, 2017). These base models are trained independently on different subsets of the training data, which are obtained via bootstrap sampling (sample randomly with replacement) from the original dataset (Smolyakov, 2017). It is usually effective on base models that are less stable, especially the one with high sensitivity to perturbation on training data (Dietterich, 2000).    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l78VSnashn5y"
   },
   "source": [
    "### Pre-processing \n",
    "\n",
    "With the code below, the following data pre-processing methods have been experimented \n",
    "\n",
    "1. scale the data with standard deviaiton\n",
    "2. fold change for feature reduction\n",
    "3. PCA for feature reduction\n",
    "4. elimilating words with low tf-idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUQ-IIAIel9H"
   },
   "outputs": [],
   "source": [
    "##Train Test Split function\n",
    "def train_test_split(X, Y, X_size = 19000, random_state = 1):\n",
    "    '''X_size specifies number of rows in training data'''\n",
    "    idx = np.random.RandomState(seed=random_state).permutation(X.shape[0])\n",
    "    trainsplit = idx[:X_size]\n",
    "    testsplit = idx[X_size:]\n",
    "    return X[trainsplit], Y[trainsplit], X[testsplit], Y[testsplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWvHtQ4Shlmr"
   },
   "outputs": [],
   "source": [
    "class FeatureReduction(object):\n",
    "    '''Input X and Y where X is in a sparse matrix'''\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        XY = scipy.sparse.hstack((Y.reshape(X.shape[0],1),X))\n",
    "        self.XY = pd.DataFrame(XY.toarray())\n",
    "    \n",
    "    def StandardDeviationFR(self, nfeatures = 10000):\n",
    "        means = self.XY.groupby(0).mean()\n",
    "        std = np.std(means, axis=0)\n",
    "        self.std = std\n",
    "        \n",
    "        index = std.sort_values(ascending=False)[:nfeatures].index\n",
    "        index = np.r_[index]\n",
    "        index -= 1\n",
    "        self.index = index\n",
    "        return index, std\n",
    "    \n",
    "    def FoldChange(self, nfeatures = 10000):\n",
    "        '''Calculates Fold change'''\n",
    "        data = self.XY + 1e-8\n",
    "        output= []\n",
    "        for i in range(data.shape[0]):\n",
    "            fold_change = []\n",
    "            for j in range(data.shape[0]):\n",
    "                fld_chng = np.abs(np.log2(data.iloc[i, 1:] / data.iloc[j, 1:]).values)\n",
    "                fold_change.append(fld_chng)\n",
    "            output.append(fold_change)\n",
    "        output = np.array(output)\n",
    "        total = []\n",
    "        for i in range(output.shape[0]):\n",
    "            mean = np.mean(output[i], axis=0)\n",
    "            total.append(mean)\n",
    "            \n",
    "        final = pd.Series(np.mean(total, axis = 0))\n",
    "        self.final = final\n",
    "        index_fld = final.sort_values(ascending=False)[:nfeatures].index\n",
    "        index = np.r_[index_fld]\n",
    "        index -= 1\n",
    "        self.index = index\n",
    "        return index, final\n",
    "    \n",
    "    def Occurence(self, nfeatures = 10000, method = 'Count'):\n",
    "        '''Two methods for ranking feature occurrence. Raw counts through Count or\n",
    "        summed feature wise sum of tf-idf values via Sum'''\n",
    "        if method  == 'Count':\n",
    "            counts = pd.DataFrame(self.X.getnnz(axis=0))\n",
    "            countssort = counts.sort_values(0, ascending = False)\n",
    "            self.occur = countssort\n",
    "            index = countssort[:nfeatures].index\n",
    "            index = np.r_[index]\n",
    "            self.index = index\n",
    "            return index, countssort\n",
    "        elif method =='Sum':\n",
    "            sums = pd.DataFrame(self.X.sum(axis = 0).T)\n",
    "            sumssort = sums.sort_values(0, ascending = False)\n",
    "            self.occur = sumssort\n",
    "            index = sumssort[:nfeatures].index\n",
    "            index = np.r_[index]\n",
    "            self.index = index\n",
    "            return index, sumssort\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Returns the dataset with reduced features'''\n",
    "        return X[:,self.index]\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "class PCA(object):\n",
    "    \"\"\"Computes a reconstructed matrix from the SVD decomposition of a n*p matrix. Not technically a PCA as we do not centre/normalize data.\n",
    "    Reason we do not scale is because it will defeat the purpose of a sparse matrix and increase the computing time. \n",
    "    \"\"\"\n",
    "    def __init__(self, components = 10):\n",
    "        self.components = components\n",
    "        \n",
    "    def fit(self, X):       \n",
    "        u, s, vt = svds(X, k = self.components)\n",
    "        S = np.diag(s[::-1])\n",
    "        n = len(s)\n",
    "        self.u = u[:,n-1::-1]\n",
    "        self.S = S\n",
    "        self.vt = vt[n-1::-1,:]\n",
    "        \n",
    "    def transform(self, X):\n",
    "        u = self.u\n",
    "        S = self.S\n",
    "        components = self.components\n",
    "        X_r = u[:,0:components].dot(S[0:components,0:components])\n",
    "        return X_r\n",
    "\n",
    "    def fit_transform(self,X):        \n",
    "        components = self.components\n",
    "        u, s, vt = svds(X, k = self.components)\n",
    "        S = np.diag(s[::-1])\n",
    "        n = len(s)\n",
    "        self.u = u[:,n-1::-1]\n",
    "        self.S = S\n",
    "        X_r = u[:,0:components].dot(S[0:components,0:components])\n",
    "        return X_r\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1_hsOaLhfTf"
   },
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjDQ8JYwhxHl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\"\"\"Multinomial Logistic Regression Classifier\n",
    ":type lr: numeric\n",
    ":param lr: the learning rate that gradient descent is performed, default to 1\n",
    "\n",
    ":type n_iter: integer\n",
    ":param n_iter: the number of iterations to perform gradient descent, default to 100\n",
    "\n",
    ":type C: numeric\n",
    ":param C: the l2 regularization coefficient, defaults to 0.1\n",
    "\n",
    ":type SGD: boolean\n",
    ":param SGD: defines whether SGD is used or not. If false then standard batch gradient descent is used, defaults to True\n",
    "\n",
    "\"\"\"\n",
    "class MultinomialLogisticRegression(object):\n",
    "    def __init__(self, lr = 1, n_iter = 100, C = 0.1, SGD = True):\n",
    "        #Initialises the parameters\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.C = C\n",
    "        self.SGD = SGD\n",
    "        \n",
    "    def fit(self, X, Y, batchsize = 218):\n",
    "        #fits the model to a dataset. Batchsize is a term that must be specified when using SGD. If not SGD it can be left as it is.\n",
    "        self.N = X.shape[0]\n",
    "        #if label shape is not dummy encoded then we dummy encode in the function\n",
    "        if Y.shape == (X.shape[0],):\n",
    "            Y = OneHotEncoding.transform(Y)\n",
    "        #Initialises the weights and bias to zeros\n",
    "        #self.weights = np.random.normal(0,2/(X.shape[1] + Y.shape[1]),(X.shape[1], Y.shape[1]))\n",
    "        self.weights = np.zeros((X.shape[1],Y.shape[1]))\n",
    "        self.bias = np.zeros((1,Y.shape[1]))\n",
    "        \n",
    "        #Iteration loop\n",
    "        for i in range(self.n_iter):  \n",
    "            #Saving costs and accuracy\n",
    "            costs = []\n",
    "            accuracy = []\n",
    "            #SGD\n",
    "            if self.SGD:\n",
    "                #split into batches\n",
    "                batchXY = zip([X[i:i+batchsize,:] for i in range(0,X.shape[0],batchsize)],\n",
    "                              [Y[i:i+batchsize,:] for i in range(0,Y.shape[0],batchsize)])\n",
    "                for batchX, batchY in batchXY:\n",
    "                    #Regularisation \n",
    "                    self.reg = self.C/(2*batchX.shape[0]) * np.sum(self.weights**2)\n",
    "                    #Get prediction output\n",
    "                    Ypred = self.output(batchX)\n",
    "                    #Get cost\n",
    "                    self.cost = self.cross_entropy(Ypred, batchY) + self.reg\n",
    "                    #Get accuracy\n",
    "                    acc = LR_get_accuracy(Ypred, batchY)\n",
    "                    #Get gradient of error\n",
    "                    costgrad = self.cost_grad(batchY)\n",
    "                    #Calculate gradient of parameters from error grad\n",
    "                    dweight, dbias = self.param_grad(batchX, costgrad)\n",
    "                    #Update parameters\n",
    "                    self.weights += -self.lr * dweight - (self.lr * ((self.C/batchX.shape[0])*self.weights))\n",
    "                    self.bias += -self.lr * dbias\n",
    "                    accuracy.append(acc)\n",
    "                    costs.append(self.cost)\n",
    "            #BatchGradientDescent\n",
    "            else:\n",
    "                self.reg = self.C/(2*X.shape[0]) * np.sum(self.weights**2)\n",
    "                Ypred = self.output(X)\n",
    "                self.cost = self.cross_entropy(Ypred, Y) + self.reg\n",
    "                acc = LR_get_accuracy(Ypred, Y)\n",
    "                costgrad = self.cost_grad(Y)\n",
    "                dweight, dbias = self.param_grad(X, costgrad)\n",
    "                self.weights += -self.lr * dweight - (self.lr * ((self.C/X.shape[0])*self.weights))\n",
    "                self.bias += -self.lr * dbias\n",
    "                accuracy.append(acc)\n",
    "                costs.append(self.cost)   \n",
    "            #print('Iteration:', i, '\\nAccuracy:', accuracy[-1], '\\nCost:', costs[-1])\n",
    "                \n",
    "    def softmax(self, x):\n",
    "        #Softmax function for multinomial logistic regression. Makes probability sum to 1\n",
    "        #We subtract the max of x from x to prevent numeric overflow\n",
    "        e_x = np.exp(x - np.max(x, axis = -1, keepdims= True))\n",
    "        return e_x / np.sum(e_x, axis = -1, keepdims = True)\n",
    "    \n",
    "    def output(self, X):\n",
    "        #Calculates an output from input and parameters\n",
    "        self.out = self.softmax(X.dot(self.weights) + self.bias)\n",
    "        return self.out\n",
    "    \n",
    "    def param_grad(self, X, output_grad):\n",
    "        #Calculates the gradient of the parameters\n",
    "        dW = X.T.dot(output_grad)\n",
    "        dB = np.sum(output_grad, axis = 0, keepdims = True)\n",
    "        return dW, dB\n",
    "    \n",
    "    def cost_grad(self, T):\n",
    "        #Calculates the gradient of the cost\n",
    "        self.costgrad = (self.out-T)/self.out.shape[0]\n",
    "        return self.costgrad\n",
    "    \n",
    "    def cross_entropy(self, output,label,epsilon = 1e-12):\n",
    "        #Calculates the loss. We clip the output value by an epsilon term to preserve numeric stability. No zero outputs\n",
    "        output = np.clip(output, epsilon, 1. -epsilon)\n",
    "        m = label.shape[0]\n",
    "        log_likelihood = np.log(output)\n",
    "        loss = -np.sum(label*log_likelihood) / m\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #A predict function that does the same thing as output but for test data.\n",
    "        out = self.softmax(X.dot(self.weights) + self.bias)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "ArixNfH0tOEf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "\n",
    "\"\"\"Multinomial Naive Bayes Classifier\n",
    ":type alpha: float\n",
    ":param alpha: laplace smoothing parameter, default to 0.01\n",
    "\n",
    ":type cv: integer\n",
    ":param cv: if cv>1, the model will run with cross validation, the value of cv is the number of fold to split; \n",
    "when cv=1, the model run without cross validation, default to 1. If cv=0 then we specify the input training and test data ourselves.\n",
    "\n",
    "In order to save memory, we wrapp data reading inside the Naive Bayes Classifier.\n",
    "Data are read and split automatically when the model.fit() function is call\n",
    "\n",
    "When run in cross validation mode, the predict function will return a list of K\n",
    "fold predictions; self.testlabel will be stored as a list of k fold labels\n",
    "\n",
    "\"\"\"\n",
    "class MultinomialNaiveBayes(object):\n",
    "    \n",
    "    def __init__(self, alpha=0.01, cv=1):\n",
    "      # wrap reading data here if run out of memory\n",
    "      self.alpha = alpha\n",
    "      self.cv = cv\n",
    "      if cv>1:\n",
    "        # record prediction result for cross validation\n",
    "        self.cv_pred = []\n",
    "        # record test labels for each fold\n",
    "        self.cv_test_labels = []\n",
    "       \n",
    "    def kfold_split(self, nrow, random_state=0):\n",
    "      k=self.cv\n",
    "      # Set random Seed\n",
    "      random.seed(random_state)\n",
    "      # Size per fold\n",
    "      fold_size = int(nrow/k)\n",
    "      # Return a list of k arrays of size=Fold_Size without replacement\n",
    "      cv_index = np.random.choice(nrow, size=(k, fold_size), replace=False)\n",
    "      return cv_index\n",
    "    \n",
    "    def fit_fold(self, X):       \n",
    "      # P(C)\n",
    "      class_prob = X.iloc[:,0].value_counts()\n",
    "      class_prob = class_prob/np.sum(class_prob)\n",
    "      # log(p(w|C))\n",
    "      class_prob_log = np.log(class_prob)\n",
    "      # sort index thus it has the same sequence as the others\n",
    "      self.class_prob_log = class_prob_log.sort_index()\n",
    "      term_prob = X.groupby(\"class\").sum() \n",
    "      #flash out X\n",
    "      X=None\n",
    "      # count(wi, Ci) + alpha\n",
    "      term_prob = term_prob + self.alpha\n",
    "      \n",
    "      #Sum_wi(P(wi|C))+alpha*number_of_features/words\n",
    "      deno=term_prob.sum(axis=1)+self.alpha*term_prob.shape[1]\n",
    "      # p(w|C)\n",
    "      wc_prob = term_prob.div(deno, axis=0)\n",
    "      # store the index of the class for wc matirx\n",
    "      class_index = wc_prob.index\n",
    "      # log(p(w|C)), negative infinity log(0) is turned to 0\n",
    "      self.wc_prob_log = csr_matrix(np.log(wc_prob).replace(-np.inf, 0.0)) \n",
    "    \n",
    "    def predict_fold(self):\n",
    "      # Sum(fi*log(P(wi|Ci)))\n",
    "      # fi is the tf-idf value of wi in test data\n",
    "      # each row represents an app\n",
    "      # each column represents the Sum(fi*log(P(wi|Ci))) value for a class\n",
    "      likelihood_matrix = self.testdata.dot(self.wc_prob_log.transpose()).toarray()\n",
    "      index=0\n",
    "      pred = []\n",
    "      probs = []\n",
    "      for likelihood_log in likelihood_matrix:\n",
    "        prob_log = likelihood_log + self.class_prob_log\n",
    "        #print(prob_log)\n",
    "        probs.append(prob_log)\n",
    "        predicted_label = prob_log.idxmax()   \n",
    "        pred.append(predicted_label)\n",
    "        index = index + 1   \n",
    "      return pred, probs\n",
    "    \n",
    "    def fit(self, X = None, Y = None, testX = None, testY = None, preload = True):\n",
    "      if preload:\n",
    "          #pre-processing data\n",
    "          traindata = pd.read_csv('training_data.csv', header=None).sort_values([0])\n",
    "          trainlabel = pd.read_csv('training_labels.csv', header=None).sort_values([0])\n",
    "          variable_name = 0\n",
    "          traindata = traindata.drop(0, 1)\n",
    "          trainlabel = trainlabel.drop(0, 1)\n",
    "          labels, trainlabel = np.unique(trainlabel, return_inverse = True)\n",
    "          traindata.insert(loc=0, column=\"class\", value=trainlabel)  \n",
    "          print(\"Finish reading the data...\")\n",
    "      else:\n",
    "          trainlabel = pd.DataFrame(Y)\n",
    "          traindata = pd.DataFrame(X.toarray())\n",
    "          traindata.insert(loc=0, column=\"class\", value=trainlabel)\n",
    "          \n",
    "      #If no cv used, we make the split outside the class.\n",
    "      if self.cv==0:\n",
    "          testdata = pd.DataFrame(testX.toarray())\n",
    "          self.testdata = testdata\n",
    "          self.testdata = self.testdata.reset_index(drop=True)\n",
    "          self.testdata = csr_matrix(self.testdata) \n",
    "          # fit the model\n",
    "          self.fit_fold(traindata)\n",
    "          \n",
    "      # if it is not cross validation\n",
    "      if self.cv==1:\n",
    "        # spliting\n",
    "        split_index=int(traindata.shape[0]*.9)\n",
    "        self.testdata = traindata[split_index:]\n",
    "        self.testdata = self.testdata.reset_index(drop=True)\n",
    "        self.testdata = self.testdata.drop([\"class\"], axis=1)\n",
    "        self.testlabel = trainlabel[split_index:] \n",
    "        # turn testing data to a csr_matrix\n",
    "        self.testdata = csr_matrix(self.testdata) \n",
    "        traindata = traindata[:split_index]\n",
    "        # fit the model\n",
    "        self.fit_fold(traindata)\n",
    "       \n",
    "      #if it is cross validation\n",
    "      if self.cv>1:\n",
    "        cv_index = self.kfold_split(traindata.shape[0])\n",
    "        # for each fold train and predict\n",
    "        for fold_number, fold_index in enumerate(cv_index):\n",
    "          print(\"Training on\"+str(fold_number)+\" fold now...\")\n",
    "          test_index = fold_index\n",
    "          train_index = [i for i in range(traindata.shape[0]) if i not in fold_index]\n",
    "          # getting k fold data    \n",
    "          self.testdata, testlabel = traindata.iloc[test_index, :], trainlabel[test_index]\n",
    "          self.testdata = self.testdata.reset_index(drop=True)\n",
    "          self.testdata = self.testdata.drop([\"class\"], axis=1)\n",
    "          self.testdata = csr_matrix(self.testdata)\n",
    "          training_data = traindata.iloc[train_index, :]\n",
    "          # record testlabel\n",
    "          self.cv_test_labels.append(testlabel)\n",
    "          # fit from model fold\n",
    "          self.fit_fold(training_data)\n",
    "          #flashout training data\n",
    "          training_data=None\n",
    "          # predict the result\n",
    "          pred=self.predict_fold()\n",
    "          self.cv_pred.append(pred)\n",
    "\n",
    "    def predict(self):  \n",
    "      # if it is cross validation\n",
    "      if self.cv>1:\n",
    "        return self.cv_pred      \n",
    "      # if it is not cross validation\n",
    "      if self.cv<1:\n",
    "        return self.predict_fold()    \n",
    "\n",
    "    \n",
    "#modelNB = MultinomialNaiveBayes(alpha=0.01, cv=10)\n",
    "#modelNB.fit()\n",
    "#pred=modelNB.predict()\n",
    "# test\n",
    "#print(np.sum(pred==modelNB.testlabel)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpSy7a6HuD13"
   },
   "outputs": [],
   "source": [
    "\"\"\"Cross Validation and Model Evaluation\"\"\"\n",
    "def LR_get_accuracy(Y, T):\n",
    "    t_positive = 0\n",
    "    for i, j in zip(Y, T):\n",
    "        predY = np.argmax(i)\n",
    "        trueY = np.argmax(j)\n",
    "        if predY == trueY:\n",
    "            t_positive += 1\n",
    "    return t_positive / T.shape[0]\n",
    "\n",
    "def NB_get_accuracy(Y, T):\n",
    "    '''Feeds in naive bayes prediction and true label list'''\n",
    "    t_positive = 0\n",
    "    for i, j in zip(Y, T):\n",
    "        predY = np.argmax(i)\n",
    "        if predY == j:\n",
    "            t_positive += 1\n",
    "    return t_positive / T.shape[0]\n",
    "  \n",
    "def metrics(pred, true, modeltype = 'LR'):\n",
    "    # Join the true and predicted labels\n",
    "    if modeltype == 'LR':\n",
    "      truth, prediction = map(np.argmax, true), map(np.argmax, pred)\n",
    "    elif modeltype == 'NB':\n",
    "      truth, prediction = true, map(np.argmax, pred)\n",
    "    truth, prediction = np.fromiter(truth, dtype=np.int), np.fromiter(prediction, dtype=np.int)\n",
    "    truth, prediction = truth.reshape(len(truth), 1), prediction.reshape(len(prediction), 1)\n",
    "    total = np.concatenate((truth, prediction), axis=1)\n",
    "    class_accuracy = []\n",
    "    \n",
    "    for label in range(30):\n",
    "        true_class_index = total[:, 0] == label\n",
    "        pred_class_index = total[:, 1] == label\n",
    "        pred_not_class_index = total[:, 1] != label\n",
    "        # TP - When the prediction equals the true Label\n",
    "        TP = np.sum(label == total[true_class_index, 1])\n",
    "        # FN - When the prediction does not equal the true label\n",
    "        FN = np.sum(label != total[true_class_index, 1])\n",
    "        # FP - When the prediction selects the class but it is not true\n",
    "        FP = np.sum(total[pred_class_index, 0] != label)\n",
    "        # When the Prediction does not select the class and the truth is not the class\n",
    "        #TN = np.sum(total[pred_not_class_index, 0] != label)\n",
    "        accuracy = TP / sum(true_class_index)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = (2 * recall * precision) / (recall + precision)\n",
    "        class_accuracy.append([label, sum(true_class_index), accuracy, precision, recall, f1_score])\n",
    "    \n",
    "    return class_accuracy\n",
    "  \n",
    "def metric_table(data):\n",
    "    summary = pd.DataFrame()\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            summary = summary.append(pd.Series(data[i][j]), ignore_index=True)\n",
    "    summary.columns = ['Label', 'Count', 'Accuracy', 'Precision', 'Recall', 'F-Score']\n",
    "    return summary\n",
    "\n",
    "def kfold_split(data, k, random_state=0):\n",
    "    # Set random Seed\n",
    "    random.seed(random_state)\n",
    "    # Number of Rows\n",
    "    nrow = data.shape[0]\n",
    "    # Size per fold\n",
    "    fold_size = int(nrow / k)\n",
    "    # Return a list of k arrays of size=Fold_Size without replacement\n",
    "    cv_index = np.random.choice(nrow, size=(k, fold_size), replace=False)\n",
    "    return cv_index\n",
    "\n",
    "\n",
    "def cross_validation(data, labels, cv_index, model,  batchsize, accuracy_function, modeltype = 'LR'):\n",
    "    total = []\n",
    "    accuracy = []\n",
    "    if modeltype == 'LR':\n",
    "      for fold_number, fold_index in enumerate(cv_index):\n",
    "          print('Fold Number:', fold_number)\n",
    "          test_index = fold_index\n",
    "          train_index = [i for i in range(traindata.shape[0]) if i not in fold_index]\n",
    "          X_train, y_train = data[train_index, :], labels[train_index]\n",
    "          X_val, y_val = data[test_index, :], labels[test_index]\n",
    "          model.fit(X_train, y_train)\n",
    "          pred = model.predict(X_val)\n",
    "          metric = metrics(pred, y_val, modeltype)\n",
    "          total.append(metric)\n",
    "          acc = accuracy_function(pred, y_val)\n",
    "          accuracy.append(acc)\n",
    "    elif modeltype =='NB':\n",
    "      for fold_number, fold_index in enumerate(cv_index):\n",
    "          print('Fold Number:', fold_number)\n",
    "          test_index = fold_index\n",
    "          train_index = [i for i in range(traindata.shape[0]) if i not in fold_index]\n",
    "          X_train, y_train = data[train_index, :], labels[train_index]\n",
    "          X_val, y_val = data[test_index, :], labels[test_index]\n",
    "          modelNB = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "          modelNB.fit(X_train, y_train, X_val, y_val, preload = False)\n",
    "          pred = np.array(modelNB.predict()[1])\n",
    "          metric = metrics(pred, y_val, modeltype)\n",
    "          total.append(metric)\n",
    "          acc = accuracy_function(pred, y_val)\n",
    "          accuracy.append(acc)\n",
    "    output = metric_table(total)\n",
    "    return output, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AihvQxCmvpJ"
   },
   "source": [
    "## Baseline\n",
    "\n",
    "First we create a baseline model. We will do a train-test split and run both models on this data. We will then use feature reduction techniques to gridsearch the best technique and number of features to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "963MAzgRnHt3",
    "outputId": "dca52ef0-f675-486a-a977-def774e6be83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 13626)\n",
      "(19000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train, X_val, y_val = train_test_split(traindata, trainlabel)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Runtime - 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CdqEQ4Tvnb6G",
    "outputId": "fe2bdb5c-be16-4111-889f-ac423c0ce9f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557971014492754"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Logistic Regression\n",
    "modelLR = MultinomialLogisticRegression(lr=20, n_iter = 40, C= 0.001, SGD = True)\n",
    "modelLR.fit(X_train, y_train, batchsize = 100)\n",
    "pred = modelLR.predict(X_val)\n",
    "LR_get_accuracy(pred, OneHotEncoding.transform(y_val)) ##Encode because the y_val is not encoded\n",
    "\n",
    "# Runtime - 28.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aamyPOAWoB23",
    "outputId": "6c1d70ee-68b6-4e96-fe57-92631a7d348d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6331521739130435"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Naive Bayes\n",
    "modelNB = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "modelNB.fit(X_train, y_train, X_val, y_val, preload = False)\n",
    "pred = np.array(modelNB.predict()[1])\n",
    "NB_get_accuracy(pred, y_val)\n",
    "\n",
    "# Runtime - 2.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hikfr0r6pLV0"
   },
   "source": [
    "### Feature reduction\n",
    "\n",
    "The Logistic Regression's baseline appears to perform better than the Naive Bayes. We will now use some feature reduction to get more informative features, removing noisy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6crtcagvIQ1e",
    "outputId": "626e51bd-fd3e-422b-fe78-aca9d8a93aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 10000)\n",
      "(19000,)\n"
     ]
    }
   ],
   "source": [
    "##Using StandardDeviation to get top 10000 features\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.StandardDeviationFR(nfeatures = 10000)\n",
    "X = FR.transform(traindata)\n",
    "\n",
    "X_train, y_train, X_val, y_val = train_test_split(X, trainlabel)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Runtime - 2.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K0R8ob9ip5vV",
    "outputId": "5eb53d5d-2ec6-4f8a-ae86-56d858dbf746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557971014492754"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Logistic Regression\n",
    "modelLR = MultinomialLogisticRegression(lr=20, n_iter = 40, C= 0.001, SGD = True)\n",
    "modelLR.fit(X_train, y_train, batchsize = 100)\n",
    "pred = modelLR.predict(X_val)\n",
    "LR_get_accuracy(pred, OneHotEncoding.transform(y_val)) ##Encode because the y_val is not encoded\n",
    "\n",
    "# Runtime - 23.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tJrkN-v6p-jG",
    "outputId": "c8c56170-5a45-40ef-d76a-5328e91cfec9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6322463768115942"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Naive Bayes\n",
    "modelNB = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "modelNB.fit(X_train, y_train, X_val, y_val, preload = False)\n",
    "pred = np.array(modelNB.predict()[1])\n",
    "NB_get_accuracy(pred, y_val)\n",
    "\n",
    "# Runtime - 2.5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ie-2_5CdqOej"
   },
   "source": [
    "Using StandardDeviation feature reduction, taking only top 10000 features appears to increase our accuracy.\n",
    "We can try using TF-IDF columnwise sums to rank the features and take 10000 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ivz60NyOIIB_",
    "outputId": "86219623-b126-49db-bc29-185d69ed9c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 10000)\n",
      "(19000,)\n"
     ]
    }
   ],
   "source": [
    "##Using TF-IDF columnwise sum rankings\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.Occurence(nfeatures = 10000, method = 'Sum')\n",
    "X = FR.transform(traindata)\n",
    "\n",
    "X_train, y_train, X_val, y_val = train_test_split(X, trainlabel)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Runtime - 1.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PaBHr3qXqjcj",
    "outputId": "90d651d4-4407-43eb-a815-07e30141729e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654891304347826"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Logistic Regression\n",
    "modelLR = MultinomialLogisticRegression(lr=20, n_iter = 40, C= 0.001, SGD = True)\n",
    "modelLR.fit(X_train, y_train, batchsize = 100)\n",
    "pred = modelLR.predict(X_val)\n",
    "LR_get_accuracy(pred, OneHotEncoding.transform(y_val)) ##Encode because the y_val is not encoded\n",
    "\n",
    "# Runtime - 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xw8xk-NAqjh5",
    "outputId": "2cffdd45-731b-4080-fabd-d942917a4c13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6286231884057971"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Naive Bayes\n",
    "modelNB = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "modelNB.fit(X_train, y_train, X_val, y_val, preload = False)\n",
    "pred = np.array(modelNB.predict()[1])\n",
    "NB_get_accuracy(pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVPB7hiXrEdA"
   },
   "source": [
    "TF-IDF columnwise sums ranking performs worse. \n",
    "\n",
    "## Grid searching optimum number of features\n",
    "\n",
    "The choice of 10000 features is arbitrary in this case. We can choose an optimum number of features for each model with a grid search. We will feed the model through different combination of features and take the feature number that produces the best metric scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "-IazBrDLTs4s",
    "outputId": "4c9d9772-b1f9-4c96-a522-af195a4e29a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFeatures: 500 LR Method 1: 0.5833333333333334 NB method 1: 0.6014492753623188 LR Method 2: 0.5498188405797102 NB method 2: 0.5480072463768116\n",
      "NFeatures: 1500 LR Method 1: 0.6231884057971014 NB method 1: 0.6186594202898551 LR Method 2: 0.6141304347826086 NB method 2: 0.6105072463768116\n",
      "NFeatures: 2500 LR Method 1: 0.6512681159420289 NB method 1: 0.6304347826086957 LR Method 2: 0.6376811594202898 NB method 2: 0.6177536231884058\n",
      "NFeatures: 3500 LR Method 1: 0.6539855072463768 NB method 1: 0.6213768115942029 LR Method 2: 0.644927536231884 NB method 2: 0.6259057971014492\n",
      "NFeatures: 4500 LR Method 1: 0.6512681159420289 NB method 1: 0.6277173913043478 LR Method 2: 0.6494565217391305 NB method 2: 0.6159420289855072\n",
      "NFeatures: 5500 LR Method 1: 0.6467391304347826 NB method 1: 0.6222826086956522 LR Method 2: 0.6512681159420289 NB method 2: 0.6186594202898551\n",
      "NFeatures: 6500 LR Method 1: 0.6512681159420289 NB method 1: 0.6277173913043478 LR Method 2: 0.644927536231884 NB method 2: 0.6240942028985508\n",
      "NFeatures: 7500 LR Method 1: 0.6503623188405797 NB method 1: 0.6277173913043478 LR Method 2: 0.6521739130434783 NB method 2: 0.6177536231884058\n",
      "NFeatures: 8500 LR Method 1: 0.6512681159420289 NB method 1: 0.6295289855072463 LR Method 2: 0.6494565217391305 NB method 2: 0.6231884057971014\n",
      "NFeatures: 9500 LR Method 1: 0.654891304347826 NB method 1: 0.6295289855072463 LR Method 2: 0.6539855072463768 NB method 2: 0.6295289855072463\n",
      "NFeatures: 10500 LR Method 1: 0.6567028985507246 NB method 1: 0.6340579710144928 LR Method 2: 0.6539855072463768 NB method 2: 0.6286231884057971\n",
      "NFeatures: 11500 LR Method 1: 0.6567028985507246 NB method 1: 0.6331521739130435 LR Method 2: 0.6557971014492754 NB method 2: 0.6322463768115942\n",
      "NFeatures: 12500 LR Method 1: 0.6567028985507246 NB method 1: 0.6340579710144928 LR Method 2: 0.6567028985507246 NB method 2: 0.6331521739130435\n",
      "NFeatures: 13500 LR Method 1: 0.6557971014492754 NB method 1: 0.6331521739130435 LR Method 2: 0.6557971014492754 NB method 2: 0.6331521739130435\n"
     ]
    }
   ],
   "source": [
    "##Lets do in steps of 1000 starting from 500 features. ##This will take a while.......\n",
    "#First method - Standard Deviation\n",
    "LRacc1 = []\n",
    "NBacc1 = []\n",
    "\n",
    "#Second method - TF-IDF sum\n",
    "LRacc2 = []\n",
    "NBacc2 = []\n",
    "\n",
    "#Nfeatures\n",
    "Nfeatures = []\n",
    "\n",
    "for i in range(500, traindata.shape[1], 1000):\n",
    "  ##First method\n",
    "  FR = FeatureReduction(traindata, trainlabel)\n",
    "  idx = FR.StandardDeviationFR(nfeatures = i)\n",
    "  X = FR.transform(traindata)\n",
    "  X_train, y_train, X_val, y_val = train_test_split(X, trainlabel)\n",
    "  ##Logistic Regression\n",
    "  modelLR = MultinomialLogisticRegression(lr=20, n_iter = 40, C= 0.001, SGD = True)\n",
    "  modelLR.fit(X_train, y_train, batchsize = 100)\n",
    "  pred = modelLR.predict(X_val)\n",
    "  lra1 = LR_get_accuracy(pred, OneHotEncoding.transform(y_val)) ##Encode because the y_val is not encoded\n",
    "  LRacc1.append(lra1)\n",
    "  ##Naive Bayes\n",
    "  modelNB = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "  modelNB.fit(X_train, y_train, X_val, y_val, preload = False)\n",
    "  pred = np.array(modelNB.predict()[1])\n",
    "  nba1 = NB_get_accuracy(pred, y_val)\n",
    "  NBacc1.append(nba1)\n",
    "  \n",
    "  ##Second Method\n",
    "  FR = FeatureReduction(traindata, trainlabel)\n",
    "  idx = FR.Occurence(nfeatures = i, method = 'Sum')\n",
    "  X = FR.transform(traindata)\n",
    "  X_train, y_train, X_val, y_val = train_test_split(X, trainlabel)\n",
    "  ##Logistic Regression\n",
    "  modelLR = MultinomialLogisticRegression(lr=20, n_iter = 40, C= 0.001, SGD = True)\n",
    "  modelLR.fit(X_train, y_train, batchsize = 100)\n",
    "  pred = modelLR.predict(X_val)\n",
    "  lra2 = LR_get_accuracy(pred, OneHotEncoding.transform(y_val)) ##Encode because the y_val is not encoded\n",
    "  LRacc2.append(lra2)\n",
    "  ##Naive Bayes\n",
    "  modelNB = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "  modelNB.fit(X_train, y_train, X_val, y_val, preload = False)\n",
    "  pred = np.array(modelNB.predict()[1])\n",
    "  nba2 = NB_get_accuracy(pred, y_val)\n",
    "  NBacc2.append(nba2)\n",
    "  \n",
    "  ##Print\n",
    "  print('NFeatures:',i, 'LR Method 1:', lra1, 'NB method 1:', nba1, 'LR Method 2:', lra2, 'NB method 2:', nba2)\n",
    "  Nfeatures.append(i)\n",
    "  \n",
    "  # Runtime - 591.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "vzyqBZ2mbImH",
    "outputId": "f6b47580-a7d4-460a-f9a2-ec49ac9efe29"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFKCAYAAADi/Q31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noP8HcvWbPlmVHWsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffabaab7208>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Nfeatures, LRacc1)\n",
    "plt.plot(Nfeatures, NBacc1)\n",
    "plt.plot(Nfeatures, LRacc2)\n",
    "plt.plot(Nfeatures, NBacc2)\n",
    "plt.legend(['Logistic Regression -SDMethod', 'Naive bayes -SDMethod', 'Logistic Regression -TFSumMethod', 'Naive bayes - TFSumMethod'], loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Runtime - 1.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yhuespasc97q"
   },
   "source": [
    "Best model appears to be logistic regression at around 10500 features using the SD feature reduction technique. Similarly the best Naive Bayes model is also at around 10500 features using the SD feature reduction technique. Thus, we will take the SD method as our preferred feature reduction. Furthermore, it seems our arbitrary number of 10000 features still works reasonably well for both models. As such, we will keep using the top 10000 features from SD method for our future models. Note that these accuracy scores are not cross validated and thus the optimum number of features may differ slightly from what is seen here. The reason cross validation was not performed in this grid search is because it would simply take too long (10 folds * 4 models * 14 iterations).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Os1-qbDXeH61"
   },
   "source": [
    "### Cross Validation of Multinomial Logistic Regression and Naive Bayes models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c1mnRFMJryQB"
   },
   "source": [
    "Explain the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXoFqpjGriaO"
   },
   "outputs": [],
   "source": [
    "##Using StandardDeviation to get top 10000 features\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.StandardDeviationFR(nfeatures = 10000)\n",
    "X = FR.transform(traindata)\n",
    "Y = OneHotEncoding.transform(trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "S12bWFO_vE0m",
    "outputId": "ce0bca6e-81f5-41b9-a750-b748013e78e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Number: 0\n",
      "Fold Number: 1\n",
      "Fold Number: 2\n",
      "Fold Number: 3\n",
      "Fold Number: 4\n",
      "Fold Number: 5\n",
      "Fold Number: 6\n",
      "Fold Number: 7\n",
      "Fold Number: 8\n",
      "Fold Number: 9\n"
     ]
    }
   ],
   "source": [
    "cv_index = kfold_split(X, 10)\n",
    "model = MultinomialLogisticRegression(lr=20, n_iter=40, C=0.001, SGD = True)\n",
    "metrictable, accuracytable = cross_validation(X, Y, cv_index, model, 100, LR_get_accuracy)\n",
    "\n",
    "# Runtime - 176.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "vu-gl1cYmGUK",
    "outputId": "92c111a0-26e5-4623-81fe-03c8d5c78f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Number: 0\n",
      "Fold Number: 1\n",
      "Fold Number: 2\n",
      "Fold Number: 3\n",
      "Fold Number: 4\n",
      "Fold Number: 5\n",
      "Fold Number: 6\n",
      "Fold Number: 7\n",
      "Fold Number: 8\n",
      "Fold Number: 9\n"
     ]
    }
   ],
   "source": [
    "##Naive Bayes\n",
    "modelNB = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "metrictableNB, accuracytableNB = cross_validation(X, trainlabel, cv_index, modelNB, 100, NB_get_accuracy, modeltype = 'NB')\n",
    "\n",
    "# Runtime - 26.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYTIPE6L35pG"
   },
   "source": [
    "The code below is for calculating the batch size for SGD, the overflow/index out of bounds error is more prominent in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "6zYGC3Qt20kZ",
    "outputId": "7c58e833-6930-4bf2-ecc2-3f81f3998a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold will have: 18094 training rows.\n",
      "Each fold will have: 2010 test rows.\n",
      "Batch size: 218 \n",
      "Number of rows per batch: 83.0\n"
     ]
    }
   ],
   "source": [
    "x = traindata.shape[0] - cv_index[0].shape[0]\n",
    "print('Each fold will have:', traindata.shape[0] - cv_index[0].shape[0], 'training rows.')\n",
    "print('Each fold will have:', cv_index[0].shape[0], 'test rows.')\n",
    "for i in range(200, 2000):\n",
    "  if x%i == 0:\n",
    "    print('Batch size:', i, '\\nNumber of rows per batch:', x/i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbAsj_rFfG3L"
   },
   "source": [
    "## **Ensembling Learning: 1. A simple ensemble model with cross validation folds** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8G5JFopCfZeD"
   },
   "source": [
    "We will first perform a train-test split and then do cross validation splits on the training data. The data we will be using is the reduced dataset from Standard Deviation feature reduction (10000 columns). The test set will never be trained on. It will mimic a real test set scenario and will give us an indication of how the ensembled model will do on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jmHeeOb_fPvf",
    "outputId": "a1184f49-8f1d-4de5-9c22-46d5634a0569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 10000)\n",
      "(19000, 30)\n",
      "(1104, 10000)\n",
      "(1104, 30)\n"
     ]
    }
   ],
   "source": [
    "##Using StandardDeviation to get top 10000 features\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.StandardDeviationFR(nfeatures = 10000)\n",
    "X = FR.transform(traindata)\n",
    "\n",
    "##Dummy encode Y here for Logistic Regression later\n",
    "y = OneHotEncoding.transform(trainlabel)\n",
    "  \n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, X_size = 19000)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Runtime - 2.4s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AnrXzwUIgaGa"
   },
   "source": [
    "Now we create our cvsplit using the kfold_split function we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "msLuhv2-gijX",
    "outputId": "f7c97acd-b02b-4d63-cc79-7400b28c04a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1900)\n"
     ]
    }
   ],
   "source": [
    "cvsplit = kfold_split(X_train, k =10)\n",
    "print(cvsplit.shape) ##These are the validation indices of the 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "7PmRZwQFg1Ny",
    "outputId": "e1198527-f3df-4994-c86a-1b6292d33290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "LRValAcc: 0.6357894736842106\n",
      "LRTestAcc: 0.657608695652174\n",
      "NBValAcc: 0.6331578947368421\n",
      "NBTestAcc: 0.6286231884057971\n",
      "Fold 2\n",
      "LRValAcc: 0.6494736842105263\n",
      "LRTestAcc: 0.6467391304347826\n",
      "NBValAcc: 0.6531578947368422\n",
      "NBTestAcc: 0.6277173913043478\n",
      "Fold 3\n",
      "LRValAcc: 0.6626315789473685\n",
      "LRTestAcc: 0.6594202898550725\n",
      "NBValAcc: 0.6478947368421053\n",
      "NBTestAcc: 0.6231884057971014\n",
      "Fold 4\n",
      "LRValAcc: 0.6426315789473684\n",
      "LRTestAcc: 0.6476449275362319\n",
      "NBValAcc: 0.621578947368421\n",
      "NBTestAcc: 0.6277173913043478\n",
      "Fold 5\n",
      "LRValAcc: 0.6436842105263157\n",
      "LRTestAcc: 0.6539855072463768\n",
      "NBValAcc: 0.6331578947368421\n",
      "NBTestAcc: 0.6222826086956522\n",
      "Fold 6\n",
      "LRValAcc: 0.64\n",
      "LRTestAcc: 0.6512681159420289\n",
      "NBValAcc: 0.6357894736842106\n",
      "NBTestAcc: 0.6295289855072463\n",
      "Fold 7\n",
      "LRValAcc: 0.6521052631578947\n",
      "LRTestAcc: 0.6539855072463768\n",
      "NBValAcc: 0.6457894736842106\n",
      "NBTestAcc: 0.6376811594202898\n",
      "Fold 8\n",
      "LRValAcc: 0.6463157894736842\n",
      "LRTestAcc: 0.657608695652174\n",
      "NBValAcc: 0.6378947368421053\n",
      "NBTestAcc: 0.6259057971014492\n",
      "Fold 9\n",
      "LRValAcc: 0.6584210526315789\n",
      "LRTestAcc: 0.6467391304347826\n",
      "NBValAcc: 0.6352631578947369\n",
      "NBTestAcc: 0.6259057971014492\n",
      "Fold 10\n",
      "LRValAcc: 0.6031578947368421\n",
      "LRTestAcc: 0.6458333333333334\n",
      "NBValAcc: 0.6263157894736842\n",
      "NBTestAcc: 0.6295289855072463\n"
     ]
    }
   ],
   "source": [
    "#### Time for Ensembling. We loop through the 10 folds and create a model for each one. We do predictions on both the validation and test dataset\n",
    "##Outputs for the LR and NB models are saved from each fold\n",
    "##This will take a while to run as we are creating 20 models in total. To reduce runtime, reduce the LR n_iter.\n",
    "modelslr = []\n",
    "modelsnb = []\n",
    "lrvala = []\n",
    "lrtestouts = []\n",
    "lrtestaccs = []\n",
    "nbvala = []\n",
    "nbtestouts = []\n",
    "nbtestaccs = []\n",
    "for i, cv in enumerate(cvsplit):\n",
    "    print('Fold', i+1)\n",
    "    trainidx = list(set(list(range(0,19000)))-set(cv))\n",
    "    ##Logistic Regression\n",
    "    modellr = MultinomialLogisticRegression(lr = 20, n_iter = 40, C = 0.001 )\n",
    "    modellr.fit(X_train[trainidx], y_train[trainidx], batchsize = 100)\n",
    "    valout = modellr.predict(X_train[cv]) ##predicting on validation\n",
    "    valacc = LR_get_accuracy(valout, y_train[cv])\n",
    "    print('LRValAcc:', valacc)\n",
    "    lrvala.append(valacc)\n",
    "    testout = modellr.predict(X_test) ##predicting on test\n",
    "    testacc = LR_get_accuracy(testout, y_test)\n",
    "    print('LRTestAcc:', testacc)\n",
    "    lrtestouts.append(testout)\n",
    "    lrtestaccs.append(testacc)\n",
    "    modelslr.append(modellr)\n",
    "    ##Naive Bayes\n",
    "    modelnb = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "    modelnb.fit(X_train[trainidx], OneHotEncoding.inverse_transform(y_train[trainidx]), \n",
    "                X_train[cv], OneHotEncoding.inverse_transform(y_train[cv]), preload = False) ##Have to reverse dummy encode Y because naive bayes does not take dummies\n",
    "    valoutnb = np.array(modelnb.predict()[1])\n",
    "    valaccnb = NB_get_accuracy(valoutnb, OneHotEncoding.inverse_transform(y_train[cv]))\n",
    "    nbvala.append(valaccnb)\n",
    "    print('NBValAcc:', valaccnb)\n",
    "    modelnb.fit(X_train[trainidx], OneHotEncoding.inverse_transform(y_train[trainidx]), X_test, OneHotEncoding.inverse_transform(y_test), preload = False)\n",
    "    testoutnb = np.array(modelnb.predict()[1])\n",
    "    testaccnb = NB_get_accuracy(testoutnb, OneHotEncoding.inverse_transform(y_test))\n",
    "    print('NBTestAcc:', testaccnb)\n",
    "    nbtestouts.append(testoutnb)\n",
    "    nbtestaccs.append(testaccnb)\n",
    "    modelsnb.append(modelnb)\n",
    "    \n",
    "# Runtime - 246.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmVOrbEmjmEX"
   },
   "source": [
    "Now we ensemble the model. We will average the outputs for each model and take the probability that is the highest as the class. Since Naive Bayes does not return probability outputs we will apply the softmax function to it. This also makes it align with the Logistic regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "1VIANHegjlYz",
    "outputId": "0f9b3b10-f7c8-4712-ec88-711e63b248fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Logistic Regression Accuracy: 0.657608695652174\n",
      "Ensembled Naive Bayes Accuracy: 0.634963768115942\n",
      "Ensembling both Logistic Regression and Naive Bayes Accuracy: 0.6539855072463768\n"
     ]
    }
   ],
   "source": [
    "##Softmax function. Same as the one built in logistic regression class\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis = -1, keepdims= True))\n",
    "    return e_x / np.sum(e_x, axis = -1, keepdims = True)\n",
    "  \n",
    "nboutssoftmaxed = [softmax(i) for i in nbtestouts]\n",
    "nbensembleout = np.mean(nboutssoftmaxed, axis = 0)  \n",
    "nbensembleacc = NB_get_accuracy(nbensembleout, OneHotEncoding.inverse_transform(y_test))\n",
    "\n",
    "lrensembleout = np.mean(lrtestouts, axis = 0)\n",
    "lrensembleacc = LR_get_accuracy(lrensembleout, y_test)\n",
    "\n",
    "##We can have a look at the accuracy for just averaging across the model folds itself\n",
    "print('Ensembled Logistic Regression Accuracy:', lrensembleacc)\n",
    "print('Ensembled Naive Bayes Accuracy:', nbensembleacc)\n",
    "##Both models seem to perform better when ensembled.\n",
    "##Now we ensemble the two models together.\n",
    "\n",
    "Ensemble = np.mean([lrensembleout, nbensembleout], axis = 0)\n",
    "print('Ensembling both Logistic Regression and Naive Bayes Accuracy:', LR_get_accuracy(Ensemble, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZVISO1-RFmu"
   },
   "source": [
    "## Ensemble Learning: 2. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1Mx2_WhR0mr"
   },
   "source": [
    "With bagging, we will sample from a subset of the data with replacement and train the model on these subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTh7rd6-QlXK"
   },
   "outputs": [],
   "source": [
    "\"\"\" a function to build index of subsets of data for bagging\"\"\"\n",
    "def bootstrap_sample(nrow, sample_size, k = 30, random_state=0):\n",
    "    # Set random Seed\n",
    "    random.seed(random_state)\n",
    "    # Return a list of k arrays of subset_index (sampling with replacement)\n",
    "    bagging_index = np.random.choice(nrow, size=(k, sample_size), replace=True)\n",
    "    return bagging_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "EpwcHtnf9fjJ",
    "outputId": "101d6d40-179f-45dd-de7c-11f142cd9ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 10000)\n",
      "(19000, 30)\n",
      "(1104, 10000)\n",
      "(1104, 30)\n"
     ]
    }
   ],
   "source": [
    "##Using StandardDeviation to get top 10000 features\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.StandardDeviationFR(nfeatures = 10000)\n",
    "X = FR.transform(traindata)\n",
    "\n",
    "##Dummy encode Y here for Logistic Regression later\n",
    "y = OneHotEncoding.transform(trainlabel)\n",
    "  \n",
    "X_train, y_train, X_val, y_val = train_test_split(X, y, X_size = 19000)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fvlPkoGk9q30",
    "outputId": "a69497a5-505e-44c3-eb9b-39ddae9a9e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10000)\n"
     ]
    }
   ],
   "source": [
    "split = bootstrap_sample(19000, 10000, k = 20)\n",
    "print(split.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "O-6BFTlv9ije",
    "outputId": "3d8fe3e2-dcb9-47ca-9a52-bd29cf7588b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "LRValAcc: 0.6340579710144928\n",
      "NBValAcc: 0.6086956521739131\n",
      "Fold 2\n",
      "LRValAcc: 0.6304347826086957\n",
      "NBValAcc: 0.6014492753623188\n",
      "Fold 3\n",
      "LRValAcc: 0.6322463768115942\n",
      "NBValAcc: 0.6041666666666666\n",
      "Fold 4\n",
      "LRValAcc: 0.6259057971014492\n",
      "NBValAcc: 0.6077898550724637\n",
      "Fold 5\n",
      "LRValAcc: 0.6231884057971014\n",
      "NBValAcc: 0.595108695652174\n",
      "Fold 6\n",
      "LRValAcc: 0.6240942028985508\n",
      "NBValAcc: 0.6014492753623188\n",
      "Fold 7\n",
      "LRValAcc: 0.6385869565217391\n",
      "NBValAcc: 0.6105072463768116\n",
      "Fold 8\n",
      "LRValAcc: 0.6322463768115942\n",
      "NBValAcc: 0.5942028985507246\n",
      "Fold 9\n",
      "LRValAcc: 0.6458333333333334\n",
      "NBValAcc: 0.6195652173913043\n",
      "Fold 10\n",
      "LRValAcc: 0.6259057971014492\n",
      "NBValAcc: 0.6068840579710145\n",
      "Fold 11\n",
      "LRValAcc: 0.6304347826086957\n",
      "NBValAcc: 0.6032608695652174\n",
      "Fold 12\n",
      "LRValAcc: 0.6141304347826086\n",
      "NBValAcc: 0.595108695652174\n",
      "Fold 13\n",
      "LRValAcc: 0.6268115942028986\n",
      "NBValAcc: 0.6059782608695652\n",
      "Fold 14\n",
      "LRValAcc: 0.6331521739130435\n",
      "NBValAcc: 0.6059782608695652\n",
      "Fold 15\n",
      "LRValAcc: 0.6413043478260869\n",
      "NBValAcc: 0.6096014492753623\n",
      "Fold 16\n",
      "LRValAcc: 0.6440217391304348\n",
      "NBValAcc: 0.6195652173913043\n",
      "Fold 17\n",
      "LRValAcc: 0.6277173913043478\n",
      "NBValAcc: 0.6096014492753623\n",
      "Fold 18\n",
      "LRValAcc: 0.6385869565217391\n",
      "NBValAcc: 0.605072463768116\n",
      "Fold 19\n",
      "LRValAcc: 0.6304347826086957\n",
      "NBValAcc: 0.5987318840579711\n",
      "Fold 20\n",
      "LRValAcc: 0.6277173913043478\n",
      "NBValAcc: 0.6086956521739131\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "##Validation data that we leave out \n",
    "lrvalouts = []\n",
    "lrvalaccs = []\n",
    "nbvalouts = []\n",
    "nbvalaccs = []\n",
    "\n",
    "for i, cv in enumerate(split):\n",
    "    print('Fold', i+1)\n",
    "    ##Logistic Regression\n",
    "    modellr = MultinomialLogisticRegression(lr = 20, n_iter = 40, C = 0.001 )\n",
    "    modellr.fit(X_train[cv], y_train[cv], batchsize = 100)\n",
    "    valoutlr = modellr.predict(X_val) ##predicting on test\n",
    "    valacclr = LR_get_accuracy(valoutlr, y_val)\n",
    "    print('LRValAcc:', valacclr)\n",
    "    lrvalouts.append(valoutlr)\n",
    "    lrvalaccs.append(valacclr)\n",
    "    ##Naive Bayes\n",
    "    modelnb = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "    modelnb.fit(X_train[cv], OneHotEncoding.inverse_transform(y_train[cv]), X_val, OneHotEncoding.inverse_transform(y_val), preload = False)\n",
    "    valoutnb = np.array(modelnb.predict()[1])\n",
    "    valaccnb = NB_get_accuracy(valoutnb, OneHotEncoding.inverse_transform(y_val))\n",
    "    print('NBValAcc:', valaccnb)\n",
    "    nbvalouts.append(valoutnb)\n",
    "    nbvalaccs.append(valaccnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fTiiSB48CARK",
    "outputId": "04dba2c1-9818-41e5-fac6-2d6ebbff441a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6730072463768116 0.6376811594202898\n",
      "0.6539855072463768\n"
     ]
    }
   ],
   "source": [
    "##Softmax function. Same as the one built in logistic regression class\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis = -1, keepdims= True))\n",
    "    return e_x / np.sum(e_x, axis = -1, keepdims = True)\n",
    "  \n",
    "nboutssoftmaxed = [softmax(i) for i in nbvalouts]\n",
    "nbensembleout = np.mean(nboutssoftmaxed, axis = 0)  \n",
    "nbensembleacc = NB_get_accuracy(nbensembleout, OneHotEncoding.inverse_transform(y_val))\n",
    "\n",
    "lrensembleout = np.mean(lrvalouts, axis = 0)\n",
    "lrensembleacc = LR_get_accuracy(lrensembleout, y_val)\n",
    "\n",
    "##We can have a look at the accuracy for just averaging across the model folds itself\n",
    "print('Ensembled Logistic Regression Accuracy:', lrensembleacc)\n",
    "print('Ensembled Naive Bayes Accuracy:', nbensembleacc)\n",
    "##Both models seem to perform better when ensembled.\n",
    "##Now we ensemble the two models together.\n",
    "\n",
    "Ensemble = np.mean([lrensembleout, nbensembleout], axis = 0)\n",
    "print('Ensembling both Logistic Regression and Naive Bayes Accuracy:', LR_get_accuracy(Ensemble, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOqXdLubLfho"
   },
   "source": [
    "## Code to run the model on test data. We will use the same bagging model but with larger bag sizes (10000 sample size > 19000 sample size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9V-q-2t-LjxC",
    "outputId": "fbc9f628-3e03-4d42-b854-9334df59d5c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 10000)\n",
      "(19000, 30)\n",
      "(1104, 10000)\n",
      "(1104, 30)\n"
     ]
    }
   ],
   "source": [
    "##Using StandardDeviation to get top 10000 features\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.StandardDeviationFR(nfeatures = 10000)\n",
    "X = FR.transform(traindata)\n",
    "\n",
    "##Dummy encode Y here for Logistic Regression later\n",
    "y = OneHotEncoding.transform(trainlabel)\n",
    "  \n",
    "X_train, y_train, X_val, y_val = train_test_split(X, y, X_size = 19000)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiNF3paKLxT_"
   },
   "outputs": [],
   "source": [
    "test_data_downloaded = drive.CreateFile({'id': '1y_YySFyibYYwQtJr6v7Qf81FqULwK7Fk'})\n",
    "test_data_downloaded.GetContentFile('test_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pm4CMSHcNQRg",
    "outputId": "aac111ea-caf1-4cbc-db56-899852e4d54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2233, 10000)\n"
     ]
    }
   ],
   "source": [
    "test = csr_matrix(pd.read_csv('test_data.csv', header = None).drop(0,1))\n",
    "\n",
    "##We must transform the test data with the same feature reduction we used in train.\n",
    "test = FR.transform(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UMbKShnrOpT5",
    "outputId": "23c3d8d8-8a22-4854-f142-6a9b731424dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 19000)\n"
     ]
    }
   ],
   "source": [
    "split = bootstrap_sample(19000, 19000, k = 20)\n",
    "print(split.shape) ##We will make 20 splits. I.e. 40 models total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "-KDUf8BoLzcY",
    "outputId": "67fecbc6-a63a-4666-c331-9066be3d590c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "LRValAcc: 0.6612318840579711\n",
      "NBValAcc: 0.6231884057971014\n",
      "Fold 2\n",
      "LRValAcc: 0.6394927536231884\n",
      "NBValAcc: 0.6240942028985508\n",
      "Fold 3\n",
      "LRValAcc: 0.6485507246376812\n",
      "NBValAcc: 0.6123188405797102\n",
      "Fold 4\n",
      "LRValAcc: 0.6431159420289855\n",
      "NBValAcc: 0.6177536231884058\n",
      "Fold 5\n",
      "LRValAcc: 0.6503623188405797\n",
      "NBValAcc: 0.6231884057971014\n",
      "Fold 6\n",
      "LRValAcc: 0.6376811594202898\n",
      "NBValAcc: 0.6086956521739131\n",
      "Fold 7\n",
      "LRValAcc: 0.6485507246376812\n",
      "NBValAcc: 0.6240942028985508\n",
      "Fold 8\n",
      "LRValAcc: 0.654891304347826\n",
      "NBValAcc: 0.6195652173913043\n",
      "Fold 9\n",
      "LRValAcc: 0.6440217391304348\n",
      "NBValAcc: 0.615036231884058\n",
      "Fold 10\n",
      "LRValAcc: 0.644927536231884\n",
      "NBValAcc: 0.6014492753623188\n",
      "Fold 11\n",
      "LRValAcc: 0.6295289855072463\n",
      "NBValAcc: 0.6268115942028986\n",
      "Fold 12\n",
      "LRValAcc: 0.6476449275362319\n",
      "NBValAcc: 0.6132246376811594\n",
      "Fold 13\n",
      "LRValAcc: 0.6585144927536232\n",
      "NBValAcc: 0.6168478260869565\n",
      "Fold 14\n",
      "LRValAcc: 0.6431159420289855\n",
      "NBValAcc: 0.6168478260869565\n",
      "Fold 15\n",
      "LRValAcc: 0.6376811594202898\n",
      "NBValAcc: 0.6123188405797102\n",
      "Fold 16\n",
      "LRValAcc: 0.6403985507246377\n",
      "NBValAcc: 0.6059782608695652\n",
      "Fold 17\n",
      "LRValAcc: 0.657608695652174\n",
      "NBValAcc: 0.6114130434782609\n",
      "Fold 18\n",
      "LRValAcc: 0.6358695652173914\n",
      "NBValAcc: 0.6114130434782609\n",
      "Fold 19\n",
      "LRValAcc: 0.6557971014492754\n",
      "NBValAcc: 0.6195652173913043\n",
      "Fold 20\n",
      "LRValAcc: 0.6385869565217391\n",
      "NBValAcc: 0.6141304347826086\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "##Validation data that we leave out \n",
    "lrvalouts = []\n",
    "lrvalaccs = []\n",
    "nbvalouts = []\n",
    "nbvalaccs = []\n",
    "\n",
    "##Actual test predictions\n",
    "lrtestout = []\n",
    "nbtestout = []\n",
    "\n",
    "for i, cv in enumerate(split):\n",
    "    print('Fold', i+1)\n",
    "    ##Logistic Regression\n",
    "    modellr = MultinomialLogisticRegression(lr = 20, n_iter = 40, C = 0.001 )\n",
    "    modellr.fit(X_train[cv], y_train[cv], batchsize = 100)\n",
    "    valoutlr = modellr.predict(X_val) ##predicting on test\n",
    "    valacclr = LR_get_accuracy(valoutlr, y_val)\n",
    "    print('LRValAcc:', valacclr)\n",
    "    lrvalouts.append(valoutlr)\n",
    "    lrvalaccs.append(valacclr)\n",
    "    ##Naive Bayes\n",
    "    modelnb = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "    modelnb.fit(X_train[cv], OneHotEncoding.inverse_transform(y_train[cv]), X_val, OneHotEncoding.inverse_transform(y_val), preload = False)\n",
    "    valoutnb = np.array(modelnb.predict()[1])\n",
    "    valaccnb = NB_get_accuracy(valoutnb, OneHotEncoding.inverse_transform(y_val))\n",
    "    print('NBValAcc:', valaccnb)\n",
    "    nbvalouts.append(valoutnb)\n",
    "    nbvalaccs.append(valaccnb)\n",
    "    ##Predict on test data\n",
    "    testoutlr = modellr.predict(test)\n",
    "    modelnb.fit(X_train[cv], OneHotEncoding.inverse_transform(y_train[cv]), test, preload = False)\n",
    "    testoutnb = np.array(modelnb.predict()[1])\n",
    "    lrtestout.append(testoutlr)\n",
    "    nbtestout.append(testoutnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ufBP2nQLRdHS",
    "outputId": "e054ecad-469a-4018-d2e8-dadc08bb4ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Logistic Regression Accuracy: 0.6702898550724637\n",
      "Ensembled Naive Bayes Accuracy: 0.6313405797101449\n",
      "Ensembling both Logistic Regression and Naive Bayes Accuracy: 0.6512681159420289\n"
     ]
    }
   ],
   "source": [
    "##Softmax function. Same as the one built in logistic regression class\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis = -1, keepdims= True))\n",
    "    return e_x / np.sum(e_x, axis = -1, keepdims = True)\n",
    "  \n",
    "nboutssoftmaxed = [softmax(i) for i in nbvalouts]\n",
    "nbensembleout = np.mean(nboutssoftmaxed, axis = 0)  \n",
    "nbensembleacc = NB_get_accuracy(nbensembleout, OneHotEncoding.inverse_transform(y_val))\n",
    "\n",
    "lrensembleout = np.mean(lrvalouts, axis = 0)\n",
    "lrensembleacc = LR_get_accuracy(lrensembleout, y_val)\n",
    "\n",
    "##We can have a look at the accuracy for just averaging across the model folds itself\n",
    "print('Ensembled Logistic Regression Accuracy:', lrensembleacc)\n",
    "print('Ensembled Naive Bayes Accuracy:', nbensembleacc)\n",
    "##Both models seem to perform better when ensembled.\n",
    "##Now we ensemble the two models together.\n",
    "\n",
    "Ensemble = np.mean([lrensembleout, nbensembleout], axis = 0)\n",
    "print('Ensembling both Logistic Regression and Naive Bayes Accuracy:', LR_get_accuracy(Ensemble, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AYYP4teCThsF",
    "outputId": "3ee6310f-7d51-4593-9b0e-3a971567f3f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2233,)"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtestensemble = np.mean(lrtestout, axis = 0)\n",
    "\n",
    "nbtestsoftmax = [softmax(i) for i in nbtestout]\n",
    "nbtestensemble = np.mean(nbtestsoftmax, axis = 0)\n",
    "\n",
    "testEnsemble = np.mean([lrtestensemble, nbtestensemble], axis = 0)\n",
    "\n",
    "##Choose which prediction to use for submission\n",
    "testpred = np.argmax(lrtestensemble, axis = 1)\n",
    "#testpred = np.argmax(testEnsemble, axis = 1)\n",
    "testpred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbkdqoWWWRHS"
   },
   "outputs": [],
   "source": [
    "#del test\n",
    "submissionfile = pd.read_csv('test_data.csv', header = None)[0]\n",
    "submissionfile = pd.concat([submissionfile, pd.Series(testpred)], axis = 1)\n",
    "print(submissionfile.head())\n",
    "\n",
    "#submissionfile.to_csv('predicted_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWFnjiN2iG1M"
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ggc68nniKM8"
   },
   "source": [
    "The metrics below were calculated using a 10-fold cross validation and compares the results of the Logistic Regression and Naive Bayes models. The models were both trained using the same train and test splits and used the first 10,000 features provided by the maximum standard deviation pre-processing method.\n",
    "\n",
    "The Logistic Regression model outperformed the Naive Bayes model with respective weighted averages of 0.65 and 0.63. The Logistic Regression also outperformed the Naive Bayes when comparing micro-averaged precision, recall and F-score.\n",
    "\n",
    "The models were also analysed on their respective performance at the categorical level. The models both struggled with the 'Lifestyle' and 'Entertainment' labels, both models producing in F-scores lower than 0.35. Moreover, both models had very low recall values for the 'Lifestyle' label, this suggests that the label was rarely selected. The frequency at which 'Lifestyle' was predicted is interesting as the distribution of classes is not equal in the task, and despite being one of the more populous classes it was predicted at the lowest relative rate. The consistency between both models in predicting the 'Lifestyle' and 'Entertainment' categories suggests that the class itself is difficult to classify using a bag of words representation. In contrast, both models performed well on the 'Weather' and 'Cards and Casino' categories, once again the similar results suggest that the metrics may rely more on the feature representation and class label rather than the applied machine learning algorithm.\n",
    "\n",
    "There was little difference between the micro and macro averages for the metrics, this is likely due to insubstantial asymmetric distribution of the class labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "Ly0I30PriU-s",
    "outputId": "44a75a76-2259-4a79-ddf4-65d8f028ee0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Count  Accuracy  Precision    Recall   F-Score\n",
      "Arcade and Action     67.1  0.641441   0.544060  0.641441  0.586827\n",
      "Books and Reference   73.0  0.646196   0.581411  0.646196  0.609290\n",
      "Brain and Puzzle      69.9  0.712926   0.654115  0.712926  0.680246\n",
      "Business              68.4  0.565206   0.615168  0.565206  0.586850\n",
      "Cards and Casino      70.3  0.898949   0.884778  0.898949  0.890069\n",
      "Casual                72.6  0.486089   0.524277  0.486089  0.502408\n",
      "Comics                35.9  0.443266   0.779967  0.443266  0.556765\n",
      "Communication         71.6  0.664749   0.560775  0.664749  0.607100\n",
      "Education             74.3  0.641221   0.665332  0.641221  0.651417\n",
      "Entertainment         69.2  0.381794   0.365002  0.381794  0.371423\n",
      "Finance               70.2  0.865184   0.803803  0.865184  0.831939\n",
      "Health and Fitness    76.6  0.758908   0.679753  0.758908  0.716811\n",
      "Libraries and Demo    47.9  0.507541   0.742302  0.507541  0.601677\n",
      "Lifestyle             72.6  0.280538   0.432320  0.280538  0.338987\n",
      "Media and Video       73.8  0.551453   0.581749  0.551453  0.564962\n",
      "Medical               65.6  0.751673   0.827105  0.751673  0.786238\n",
      "Music and Audio       72.5  0.747468   0.667504  0.747468  0.703043\n",
      "News and Magazines    71.0  0.789280   0.799543  0.789280  0.793160\n",
      "Personalization       71.5  0.811171   0.596004  0.811171  0.685098\n",
      "Photography           72.8  0.742486   0.735787  0.742486  0.735992\n",
      "Productivity          65.6  0.435794   0.441837  0.435794  0.430388\n",
      "Racing                65.4  0.754899   0.807937  0.754899  0.779569\n",
      "Shopping              72.3  0.771452   0.789250  0.771452  0.778984\n",
      "Social                72.6  0.594722   0.628745  0.594722  0.608865\n",
      "Sports                62.1  0.733183   0.830355  0.733183  0.777456\n",
      "Sports Games          43.1  0.591425   0.813784  0.591425  0.679927\n",
      "Tools                 70.9  0.477972   0.458338  0.477972  0.463680\n",
      "Transportation        71.5  0.768781   0.651965  0.768781  0.705058\n",
      "Travel and Local      71.3  0.612921   0.651202  0.612921  0.630059\n",
      "Weather               48.4  0.887605   0.856244  0.887605  0.869109\n"
     ]
    }
   ],
   "source": [
    "metrictable = metrictable.groupby('Label').mean() \n",
    "metrictable.index = pd.Series(labels)\n",
    "print(metrictable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "LYmnJcjnDmRX",
    "outputId": "798a2c09-e3fc-407b-e18f-8979e9fdac88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Count  Accuracy  Precision    Recall   F-Score\n",
      "Arcade and Action     67.0  0.675102   0.523550  0.675102  0.587909\n",
      "Books and Reference   73.0  0.555424   0.600841  0.555424  0.575890\n",
      "Brain and Puzzle      69.9  0.696042   0.645307  0.696042  0.668137\n",
      "Business              68.4  0.543849   0.558600  0.543849  0.548368\n",
      "Cards and Casino      70.3  0.885160   0.903173  0.885160  0.893244\n",
      "Casual                72.5  0.486196   0.497427  0.486196  0.489740\n",
      "Comics                35.9  0.370241   0.765843  0.370241  0.495745\n",
      "Communication         71.6  0.587819   0.556519  0.587819  0.570485\n",
      "Education             74.3  0.665447   0.633244  0.665447  0.645095\n",
      "Entertainment         69.2  0.328408   0.396962  0.328408  0.355330\n",
      "Finance               70.2  0.861855   0.808935  0.861855  0.832752\n",
      "Health and Fitness    76.6  0.747486   0.705226  0.747486  0.723068\n",
      "Libraries and Demo    47.9  0.410955   0.864895  0.410955  0.549942\n",
      "Lifestyle             72.6  0.267394   0.417765  0.267394  0.323551\n",
      "Media and Video       73.8  0.534563   0.570629  0.534563  0.551448\n",
      "Medical               65.7  0.804537   0.813266  0.804537  0.806410\n",
      "Music and Audio       72.5  0.716016   0.650516  0.716016  0.678786\n",
      "News and Magazines    71.0  0.730029   0.775849  0.730029  0.748979\n",
      "Personalization       71.4  0.761373   0.595922  0.761373  0.665307\n",
      "Photography           72.8  0.783621   0.636725  0.783621  0.700207\n",
      "Productivity          65.6  0.407789   0.382957  0.407789  0.392361\n",
      "Racing                65.4  0.766372   0.754731  0.766372  0.758404\n",
      "Shopping              72.3  0.773774   0.726941  0.773774  0.748280\n",
      "Social                72.6  0.575094   0.604732  0.575094  0.588571\n",
      "Sports                62.1  0.726337   0.822509  0.726337  0.769775\n",
      "Sports Games          43.2  0.585645   0.763816  0.585645  0.658594\n",
      "Tools                 70.9  0.511636   0.408819  0.511636  0.452330\n",
      "Transportation        71.6  0.740971   0.688122  0.740971  0.712464\n",
      "Travel and Local      71.3  0.645035   0.636623  0.645035  0.639314\n",
      "Weather               48.4  0.861538   0.829662  0.861538  0.844326\n"
     ]
    }
   ],
   "source": [
    "metrictableNB = metrictableNB.groupby('Label').mean() \n",
    "metrictableNB.index = pd.Series(labels)\n",
    "print(metrictableNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ha5Koq013xJ4",
    "outputId": "fe94cc64-adf8-4909-9186-28273139083e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Average:\n",
      "Count        67.000000\n",
      "Accuracy      0.650543\n",
      "Precision     0.665680\n",
      "Recall        0.650543\n",
      "F-Score       0.650780\n",
      "dtype: float64\n",
      "0.653681592039801\n"
     ]
    }
   ],
   "source": [
    "print('Micro Average - Logistic Regression:')\n",
    "print(np.mean(metrictable, axis=0))\n",
    "print(np.mean(accuracytable, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "RfPd-z7nL65J",
    "outputId": "f970e86f-b7da-45f1-9e77-342615b9bcd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Average - Naive Bayes:\n",
      "Count        67.000000\n",
      "Accuracy      0.633524\n",
      "Precision     0.651337\n",
      "Recall        0.633524\n",
      "F-Score       0.632494\n",
      "dtype: float64\n",
      "0.6372636815920398\n"
     ]
    }
   ],
   "source": [
    "print('Micro Average - Naive Bayes:')\n",
    "print(np.mean(metrictableNB, axis=0))\n",
    "print(np.mean(accuracytableNB, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "wbGqHdTb4qCX",
    "outputId": "69c9e680-20b7-4748-b87d-09ccc98c6874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Average:\n",
      "Weighted Accuracy     0.653756\n",
      "Weighted Precision    0.657704\n",
      "Weighted Recall       0.653756\n",
      "Weighted F-Score      0.649558\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "metrictable['Weighted Accuracy'] = metrictable['Count'] * metrictable['Accuracy']\n",
    "metrictable['Weighted Precision'] = metrictable['Count'] * metrictable['Precision']\n",
    "metrictable['Weighted Recall'] = metrictable['Count'] * metrictable['Recall']\n",
    "metrictable['Weighted F-Score'] = metrictable['Count'] * metrictable['F-Score']\n",
    "\n",
    "print('Micro Average:')\n",
    "print(np.sum(metrictable[['Weighted Accuracy', 'Weighted Precision', 'Weighted Recall', 'Weighted F-Score']], axis=0)/2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_xa-3K1iUS_"
   },
   "source": [
    "## Extensive Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avGE-c9zieOc"
   },
   "source": [
    "The plot below shows how each model's accuracy is effected by introducing new feautres, the plot compares the rate of learning between two of our pre-processing feature selection methods. The plot shows that the standard deviation method outperforms the TF-IDF for both models. The models are able to learn with less features using the standard deviation method, they are able to exceed the maximum accuracy of the TF-IDF method with only 2500 (~20%) of the available features.\n",
    "\n",
    "The difference in performance between the two models is likely attributable to nature of a topic classification task. Models tend to learn to differentiation between topics or groups by learning which words appear at a disproportionate level in one class compared to others. Therefore, as opposed to summing the values per word and choosing the most frequent column, the standard deviation prioritises words which can be used to separate classes.\n",
    "\n",
    "In addition to comparing the pre-processing methods, the plot allows us to analyse an optimal cut-off for the model complexity. Given that the logistic regression model can run a 10-fold cross validation with 10,000 features in 3 minutes, the duration of the model is less of a concern. However, if applying the same model to a larger dataset we could consider changing the complexity of the model. Moreover, analysis of the model's complexity is also important in reducing the model's propensity to over fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "IEl4Jjo6ifu1",
    "outputId": "e24dde34-439b-40fa-9178-356164409afc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFKCAYAAADi/Q31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noP8HcvWbPlmVHWsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4819f38d68>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Nfeatures, LRacc1)\n",
    "plt.plot(Nfeatures, NBacc1)\n",
    "plt.plot(Nfeatures, LRacc2)\n",
    "plt.plot(Nfeatures, NBacc2)\n",
    "plt.legend(['Logistic Regression -SDMethod', 'Naive bayes -SDMethod', 'Logistic Regression -TFSumMethod', 'Naive bayes - TFSumMethod'], loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Runtime - 1.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GIpX6RosHjZT"
   },
   "source": [
    "The difference in accuracy between 3500 features and 10500 features seems to be negligible when using logistic regression. As we prefer to always use fewer features, we will run a cross validation of the logistic regression model on the top 3500 features from the SD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kB00wG-FHRK_"
   },
   "outputs": [],
   "source": [
    "##Using StandardDeviation to get top 3500 features\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.StandardDeviationFR(nfeatures = 3500)\n",
    "X = FR.transform(traindata)\n",
    "Y = OneHotEncoding.transform(trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "4NgJnK4aHRNV",
    "outputId": "e8fe9241-ced8-47e1-8faf-4c7b2f347d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Number: 0\n",
      "Fold Number: 1\n",
      "Fold Number: 2\n",
      "Fold Number: 3\n",
      "Fold Number: 4\n",
      "Fold Number: 5\n",
      "Fold Number: 6\n",
      "Fold Number: 7\n",
      "Fold Number: 8\n",
      "Fold Number: 9\n"
     ]
    }
   ],
   "source": [
    "cv_index = kfold_split(X, 10)\n",
    "model = MultinomialLogisticRegression(lr=15, n_iter=40, C=0.001, SGD = True)\n",
    "metrictable, accuracytable = cross_validation(X, Y, cv_index, model, 100, LR_get_accuracy)\n",
    "\n",
    "# Runtime - 176.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "e0cfegUZH532",
    "outputId": "2125e68e-17a1-4bee-c068-1acab0fe4f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Count  Accuracy  Precision    Recall   F-Score\n",
      "Arcade and Action     67.1  0.665752   0.548468  0.665752  0.600007\n",
      "Books and Reference   73.0  0.634280   0.560733  0.634280  0.593893\n",
      "Brain and Puzzle      69.9  0.715489   0.675078  0.715489  0.694061\n",
      "Business              68.3  0.564644   0.596143  0.564644  0.579263\n",
      "Cards and Casino      70.3  0.893854   0.865198  0.893854  0.878640\n",
      "Casual                72.6  0.504758   0.552735  0.504758  0.525856\n",
      "Comics                35.9  0.419912   0.773731  0.419912  0.541759\n",
      "Communication         71.6  0.676222   0.548767  0.676222  0.605307\n",
      "Education             74.3  0.606752   0.648747  0.606752  0.626609\n",
      "Entertainment         69.0  0.391089   0.381139  0.391089  0.383353\n",
      "Finance               70.2  0.875931   0.782380  0.875931  0.825746\n",
      "Health and Fitness    76.6  0.741524   0.676864  0.741524  0.707132\n",
      "Libraries and Demo    47.8  0.512422   0.748644  0.512422  0.603770\n",
      "Lifestyle             72.6  0.294378   0.444778  0.294378  0.350296\n",
      "Media and Video       73.8  0.570743   0.560819  0.570743  0.563683\n",
      "Medical               65.7  0.760525   0.808100  0.760525  0.782899\n",
      "Music and Audio       72.5  0.750982   0.674050  0.750982  0.709888\n",
      "News and Magazines    71.0  0.781068   0.805544  0.781068  0.792485\n",
      "Personalization       71.5  0.818374   0.599670  0.818374  0.691271\n",
      "Photography           72.9  0.748124   0.724259  0.748124  0.734817\n",
      "Productivity          65.6  0.374367   0.447126  0.374367  0.406135\n",
      "Racing                65.4  0.751544   0.821946  0.751544  0.783552\n",
      "Shopping              72.3  0.771957   0.788801  0.771957  0.777568\n",
      "Social                72.6  0.596647   0.642068  0.596647  0.616904\n",
      "Sports                62.1  0.716092   0.814254  0.716092  0.761683\n",
      "Sports Games          43.2  0.568076   0.802867  0.568076  0.663081\n",
      "Tools                 70.9  0.499185   0.434473  0.499185  0.461753\n",
      "Transportation        71.6  0.764807   0.650698  0.764807  0.701580\n",
      "Travel and Local      71.3  0.604417   0.676898  0.604417  0.636436\n",
      "Weather               48.4  0.901867   0.864380  0.901867  0.881658\n"
     ]
    }
   ],
   "source": [
    "metrictable = metrictable.groupby('Label').mean() \n",
    "metrictable.index = pd.Series(labels)\n",
    "print(metrictable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "RWsk6PcuH_kN",
    "outputId": "e2c42bd9-287d-4fd5-f721-f74304f1e7df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Average:\n",
      "Weighted Accuracy     0.653005\n",
      "Weighted Precision    0.656069\n",
      "Weighted Recall       0.653005\n",
      "Weighted F-Score      0.648500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "metrictable['Weighted Accuracy'] = metrictable['Count'] * metrictable['Accuracy']\n",
    "metrictable['Weighted Precision'] = metrictable['Count'] * metrictable['Precision']\n",
    "metrictable['Weighted Recall'] = metrictable['Count'] * metrictable['Recall']\n",
    "metrictable['Weighted F-Score'] = metrictable['Count'] * metrictable['F-Score']\n",
    "\n",
    "print('Micro Average:')\n",
    "print(np.sum(metrictable[['Weighted Accuracy', 'Weighted Precision', 'Weighted Recall', 'Weighted F-Score']], axis=0)/2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sx24wC9WKSPH"
   },
   "source": [
    "Given that the performance of the 3500 features model is only a little bit worse than the 10000 features model, we can try our bagging on the training data with 3500 features and examine our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "DmViqT_0KRXr",
    "outputId": "8b64e9e2-9dbc-4c1a-8e9e-aeed01a49255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 3500)\n",
      "(19000, 30)\n",
      "(1104, 3500)\n",
      "(1104, 30)\n",
      "(20, 19000)\n"
     ]
    }
   ],
   "source": [
    "##Using StandardDeviation to get top 3500 features\n",
    "FR = FeatureReduction(traindata, trainlabel)\n",
    "idx = FR.StandardDeviationFR(nfeatures = 3500)\n",
    "X = FR.transform(traindata)\n",
    "\n",
    "##Dummy encode Y here for Logistic Regression later\n",
    "y = OneHotEncoding.transform(trainlabel)\n",
    "  \n",
    "X_train, y_train, X_val, y_val = train_test_split(X, y, X_size = 19000)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "split = bootstrap_sample(19000, 19000, k = 20)\n",
    "print(split.shape) ##We will make 20 splits. I.e. 40 models total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rsEc1bqOGKS"
   },
   "outputs": [],
   "source": [
    "test_data_downloaded = drive.CreateFile({'id': '1y_YySFyibYYwQtJr6v7Qf81FqULwK7Fk'})\n",
    "test_data_downloaded.GetContentFile('test_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j9mKO-vKKszI",
    "outputId": "f39bf547-1ca1-403c-85b2-9f2b0bd3dad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2233, 3500)\n"
     ]
    }
   ],
   "source": [
    "test = csr_matrix(pd.read_csv('test_data.csv', header = None).drop(0,1))\n",
    "\n",
    "##We must transform the test data with the same feature reduction we used in train.\n",
    "test = FR.transform(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "mSGhxuFQKiGR",
    "outputId": "eaed64c1-6719-46b9-c8c9-70e94602a93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "LRValAcc: 0.644927536231884\n",
      "NBValAcc: 0.6268115942028986\n",
      "Fold 2\n",
      "LRValAcc: 0.6358695652173914\n",
      "NBValAcc: 0.6123188405797102\n",
      "Fold 3\n",
      "LRValAcc: 0.6286231884057971\n",
      "NBValAcc: 0.6240942028985508\n",
      "Fold 4\n",
      "LRValAcc: 0.6494565217391305\n",
      "NBValAcc: 0.625\n",
      "Fold 5\n",
      "LRValAcc: 0.634963768115942\n",
      "NBValAcc: 0.6114130434782609\n",
      "Fold 6\n",
      "LRValAcc: 0.6286231884057971\n",
      "NBValAcc: 0.615036231884058\n",
      "Fold 7\n",
      "LRValAcc: 0.634963768115942\n",
      "NBValAcc: 0.6132246376811594\n",
      "Fold 8\n",
      "LRValAcc: 0.6394927536231884\n",
      "NBValAcc: 0.6168478260869565\n",
      "Fold 9\n",
      "LRValAcc: 0.6403985507246377\n",
      "NBValAcc: 0.6123188405797102\n",
      "Fold 10\n",
      "LRValAcc: 0.6331521739130435\n",
      "NBValAcc: 0.6105072463768116\n",
      "Fold 11\n",
      "LRValAcc: 0.6367753623188406\n",
      "NBValAcc: 0.6195652173913043\n",
      "Fold 12\n",
      "LRValAcc: 0.6485507246376812\n",
      "NBValAcc: 0.6277173913043478\n",
      "Fold 13\n",
      "LRValAcc: 0.6585144927536232\n",
      "NBValAcc: 0.6204710144927537\n",
      "Fold 14\n",
      "LRValAcc: 0.6177536231884058\n",
      "NBValAcc: 0.6105072463768116\n",
      "Fold 15\n",
      "LRValAcc: 0.6385869565217391\n",
      "NBValAcc: 0.6159420289855072\n",
      "Fold 16\n",
      "LRValAcc: 0.634963768115942\n",
      "NBValAcc: 0.6132246376811594\n",
      "Fold 17\n",
      "LRValAcc: 0.6358695652173914\n",
      "NBValAcc: 0.634963768115942\n",
      "Fold 18\n",
      "LRValAcc: 0.6313405797101449\n",
      "NBValAcc: 0.6132246376811594\n",
      "Fold 19\n",
      "LRValAcc: 0.6222826086956522\n",
      "NBValAcc: 0.6141304347826086\n",
      "Fold 20\n",
      "LRValAcc: 0.6403985507246377\n",
      "NBValAcc: 0.6213768115942029\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "##Validation data that we leave out \n",
    "lrvalouts = []\n",
    "lrvalaccs = []\n",
    "nbvalouts = []\n",
    "nbvalaccs = []\n",
    "\n",
    "##Actual test predictions\n",
    "lrtestout = []\n",
    "nbtestout = []\n",
    "\n",
    "for i, cv in enumerate(split):\n",
    "    print('Fold', i+1)\n",
    "    ##Logistic Regression\n",
    "    modellr = MultinomialLogisticRegression(lr = 20, n_iter = 40, C = 0.001 )\n",
    "    modellr.fit(X_train[cv], y_train[cv], batchsize = 100)\n",
    "    valoutlr = modellr.predict(X_val) ##predicting on test\n",
    "    valacclr = LR_get_accuracy(valoutlr, y_val)\n",
    "    print('LRValAcc:', valacclr)\n",
    "    lrvalouts.append(valoutlr)\n",
    "    lrvalaccs.append(valacclr)\n",
    "    ##Naive Bayes\n",
    "    modelnb = MultinomialNaiveBayes(alpha=0.01, cv=0)\n",
    "    modelnb.fit(X_train[cv], OneHotEncoding.inverse_transform(y_train[cv]), X_val, OneHotEncoding.inverse_transform(y_val), preload = False)\n",
    "    valoutnb = np.array(modelnb.predict()[1])\n",
    "    valaccnb = NB_get_accuracy(valoutnb, OneHotEncoding.inverse_transform(y_val))\n",
    "    print('NBValAcc:', valaccnb)\n",
    "    nbvalouts.append(valoutnb)\n",
    "    nbvalaccs.append(valaccnb)\n",
    "    ##Predict on test data\n",
    "    testoutlr = modellr.predict(test)\n",
    "    modelnb.fit(X_train[cv], OneHotEncoding.inverse_transform(y_train[cv]), test, preload = False)\n",
    "    testoutnb = np.array(modelnb.predict()[1])\n",
    "    lrtestout.append(testoutlr)\n",
    "    nbtestout.append(testoutnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Z_bcnU9JK4cZ",
    "outputId": "04310326-623d-4b44-8e83-7757aab25344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Logistic Regression Accuracy: 0.6657608695652174\n",
      "Ensembled Naive Bayes Accuracy: 0.6177536231884058\n",
      "Ensembling both Logistic Regression and Naive Bayes Accuracy: 0.6621376811594203\n"
     ]
    }
   ],
   "source": [
    "##Softmax function. Same as the one built in logistic regression class\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis = -1, keepdims= True))\n",
    "    return e_x / np.sum(e_x, axis = -1, keepdims = True)\n",
    "  \n",
    "nboutssoftmaxed = [softmax(i) for i in nbvalouts]\n",
    "nbensembleout = np.mean(nboutssoftmaxed, axis = 0)  \n",
    "nbensembleacc = NB_get_accuracy(nbensembleout, OneHotEncoding.inverse_transform(y_val))\n",
    "\n",
    "lrensembleout = np.mean(lrvalouts, axis = 0)\n",
    "lrensembleacc = LR_get_accuracy(lrensembleout, y_val)\n",
    "\n",
    "##We can have a look at the accuracy for just averaging across the model folds itself\n",
    "print('Ensembled Logistic Regression Accuracy:', lrensembleacc)\n",
    "print('Ensembled Naive Bayes Accuracy:', nbensembleacc)\n",
    "##Both models seem to perform better when ensembled.\n",
    "##Now we ensemble the two models together.\n",
    "\n",
    "Ensemble = np.mean([lrensembleout, nbensembleout], axis = 0)\n",
    "print('Ensembling both Logistic Regression and Naive Bayes Accuracy:', LR_get_accuracy(Ensemble, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-1vm5dqMijn"
   },
   "source": [
    "**Now we can create our test predictions**\n",
    "\n",
    "Although the ensembling of both logistic regression and naive bayes may improve the overall accuracy in certain scenarios, in most cases the ensembled logistic regression performs the best. As such, we will take the ensembled logistic regression output as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FGfk13-fLUip",
    "outputId": "9a95420e-775b-44e9-cbc5-1826a1da260a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2233,)\n",
      "(2233, 3500)\n"
     ]
    }
   ],
   "source": [
    "lrtestensemble = np.mean(lrtestout, axis = 0)\n",
    "\n",
    "nbtestsoftmax = [softmax(i) for i in nbtestout]\n",
    "nbtestensemble = np.mean(nbtestsoftmax, axis = 0)\n",
    "\n",
    "testEnsemble = np.mean([lrtestensemble, nbtestensemble], axis = 0)\n",
    "\n",
    "##Choose which prediction to use for submission\n",
    "testpred = np.argmax(lrtestensemble, axis = 1) ##Only logistic regression\n",
    "#testpred = np.argmax(testEnsemble, axis = 1) ##Ensembled Logistic Regression and Naive Bayes\n",
    "print(testpred.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieDajbOBXB7G"
   },
   "outputs": [],
   "source": [
    "Labels = pd.DataFrame(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ANlsYbmRXs6M",
    "outputId": "0e5d964a-714e-44b8-c863-a1e5788ecc65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brain and Puzzle', 'Travel and Local', 'Productivity', 'Health and Fitness', 'Books and Reference', 'Communication', 'Entertainment', 'Transportation', 'Casual', 'Productivity', 'Health and Fitness', 'Books and Reference', 'Transportation', 'Casual', 'Business', 'Books and Reference', 'Communication', 'Books and Reference', 'Books and Reference', 'Health and Fitness', 'Libraries and Demo', 'Media and Video', 'Shopping', 'Cards and Casino', 'Shopping', 'Brain and Puzzle', 'Shopping', 'Books and Reference', 'Books and Reference', 'Finance', 'Communication', 'Photography', 'Cards and Casino', 'Racing', 'Books and Reference', 'Casual', 'Media and Video', 'Cards and Casino', 'Music and Audio', 'Transportation', 'Tools', 'Travel and Local', 'Entertainment', 'Casual', 'Personalization', 'Arcade and Action', 'Comics', 'Photography', 'Shopping', 'Education', 'Health and Fitness', 'Social', 'Social', 'Brain and Puzzle', 'Productivity', 'Brain and Puzzle', 'Arcade and Action', 'Weather', 'Travel and Local', 'Business', 'Arcade and Action', 'Books and Reference', 'Social', 'Social', 'Books and Reference', 'Communication', 'Education', 'Education', 'Lifestyle', 'News and Magazines', 'Business', 'Productivity', 'Entertainment', 'Books and Reference', 'Transportation', 'Entertainment', 'Entertainment', 'Transportation', 'Photography', 'Arcade and Action', 'Entertainment', 'Personalization', 'Photography', 'Books and Reference', 'Arcade and Action', 'Music and Audio', 'Finance', 'Medical', 'Racing', 'Music and Audio', 'Travel and Local', 'Photography', 'Health and Fitness', 'Photography', 'Media and Video', 'Sports', 'Entertainment', 'Comics', 'Communication', 'Entertainment', 'Social', 'Racing', 'News and Magazines', 'Productivity', 'Casual', 'Tools', 'Personalization', 'Photography', 'Finance', 'Cards and Casino', 'Entertainment', 'Travel and Local', 'Weather', 'Lifestyle', 'Entertainment', 'Arcade and Action', 'Music and Audio', 'Lifestyle', 'Personalization', 'Productivity', 'Transportation', 'Entertainment', 'Books and Reference', 'Sports', 'Casual', 'Sports', 'News and Magazines', 'Photography', 'Books and Reference', 'Music and Audio', 'Music and Audio', 'Music and Audio', 'Brain and Puzzle', 'Comics', 'Transportation', 'Photography', 'Books and Reference', 'Medical', 'Racing', 'Communication', 'Music and Audio', 'Business', 'Personalization', 'Music and Audio', 'Personalization', 'Business', 'Photography', 'Health and Fitness', 'Photography', 'Personalization', 'Shopping', 'Communication', 'Books and Reference', 'Racing', 'Media and Video', 'Transportation', 'Arcade and Action', 'Education', 'Communication', 'Books and Reference', 'Travel and Local', 'Business', 'Entertainment', 'Cards and Casino', 'Music and Audio', 'Racing', 'Communication', 'Personalization', 'Arcade and Action', 'Tools', 'Tools', 'Travel and Local', 'Brain and Puzzle', 'News and Magazines', 'Tools', 'Racing', 'Brain and Puzzle', 'Weather', 'Finance', 'Shopping', 'Medical', 'Transportation', 'Brain and Puzzle', 'Transportation', 'Brain and Puzzle', 'Comics', 'Communication', 'Photography', 'Education', 'Tools', 'Business', 'Personalization', 'Communication', 'Personalization', 'Finance', 'Casual', 'Business', 'Health and Fitness', 'Music and Audio', 'Travel and Local', 'Arcade and Action', 'Music and Audio', 'Racing', 'Tools', 'Books and Reference', 'Entertainment', 'Transportation', 'Brain and Puzzle', 'Cards and Casino', 'Business', 'Casual', 'Music and Audio', 'Personalization', 'Productivity', 'Personalization', 'Brain and Puzzle', 'Finance', 'Communication', 'Arcade and Action', 'Books and Reference', 'Business', 'Books and Reference', 'Tools', 'Finance', 'Education', 'Lifestyle', 'Lifestyle', 'Cards and Casino', 'Photography', 'Social', 'Tools', 'Shopping', 'Brain and Puzzle', 'Social', 'Business', 'Medical', 'Transportation', 'Social', 'Communication', 'Health and Fitness', 'Sports Games', 'Finance', 'Music and Audio', 'Finance', 'Media and Video', 'Productivity', 'Comics', 'Brain and Puzzle', 'Lifestyle', 'Photography', 'Productivity', 'Tools', 'Sports Games', 'Libraries and Demo', 'Productivity', 'Business', 'Travel and Local', 'Finance', 'Personalization', 'Libraries and Demo', 'Social', 'Social', 'Personalization', 'Shopping', 'Casual', 'Racing', 'Books and Reference', 'Social', 'Photography', 'Books and Reference', 'Health and Fitness', 'Finance', 'Books and Reference', 'News and Magazines', 'Transportation', 'Productivity', 'Communication', 'Sports', 'Communication', 'Media and Video', 'Photography', 'Casual', 'Books and Reference', 'Racing', 'Social', 'Weather', 'Communication', 'Media and Video', 'Sports', 'Arcade and Action', 'Travel and Local', 'Sports Games', 'Books and Reference', 'Personalization', 'Shopping', 'Productivity', 'Education', 'Personalization', 'Brain and Puzzle', 'Lifestyle', 'Cards and Casino', 'Cards and Casino', 'Business', 'Brain and Puzzle', 'Racing', 'Racing', 'Shopping', 'Photography', 'Casual', 'Shopping', 'News and Magazines', 'Lifestyle', 'Arcade and Action', 'Weather', 'Medical', 'Comics', 'Health and Fitness', 'Music and Audio', 'Health and Fitness', 'Travel and Local', 'Entertainment', 'Media and Video', 'Communication', 'Arcade and Action', 'Health and Fitness', 'Weather', 'Tools', 'Casual', 'Casual', 'Weather', 'Entertainment', 'Travel and Local', 'Education', 'Personalization', 'Brain and Puzzle', 'Shopping', 'Finance', 'Music and Audio', 'Media and Video', 'News and Magazines', 'Sports', 'Casual', 'Photography', 'Social', 'Medical', 'Lifestyle', 'Shopping', 'Medical', 'Arcade and Action', 'Arcade and Action', 'Casual', 'Brain and Puzzle', 'Finance', 'Finance', 'Weather', 'Weather', 'Weather', 'News and Magazines', 'Tools', 'Finance', 'Shopping', 'Brain and Puzzle', 'Sports', 'Arcade and Action', 'Weather', 'Finance', 'Medical', 'Education', 'Business', 'Music and Audio', 'Health and Fitness', 'Education', 'Photography', 'Casual', 'Racing', 'Transportation', 'Brain and Puzzle', 'Personalization', 'Cards and Casino', 'Music and Audio', 'Arcade and Action', 'Weather', 'Entertainment', 'Education', 'News and Magazines', 'Sports', 'Casual', 'Books and Reference', 'Brain and Puzzle', 'Tools', 'Transportation', 'Entertainment', 'Business', 'Brain and Puzzle', 'News and Magazines', 'Weather', 'Sports', 'Personalization', 'Finance', 'Brain and Puzzle', 'Transportation', 'Photography', 'Health and Fitness', 'Sports', 'Finance', 'Racing', 'Arcade and Action', 'Cards and Casino', 'Travel and Local', 'Sports', 'Lifestyle', 'Education', 'Music and Audio', 'Personalization', 'Communication', 'Music and Audio', 'Books and Reference', 'Libraries and Demo', 'Transportation', 'Transportation', 'Tools', 'Weather', 'Finance', 'Arcade and Action', 'Tools', 'News and Magazines', 'Libraries and Demo', 'Casual', 'Personalization', 'Music and Audio', 'Tools', 'Photography', 'Cards and Casino', 'Cards and Casino', 'Tools', 'Health and Fitness', 'Sports Games', 'Health and Fitness', 'Casual', 'Entertainment', 'Lifestyle', 'Lifestyle', 'Health and Fitness', 'Entertainment', 'Shopping', 'Shopping', 'Finance', 'Tools', 'Personalization', 'Sports Games', 'Music and Audio', 'Cards and Casino', 'Finance', 'Social', 'Books and Reference', 'Books and Reference', 'Finance', 'Communication', 'Sports', 'Libraries and Demo', 'Tools', 'Brain and Puzzle', 'Transportation', 'Health and Fitness', 'Entertainment', 'Lifestyle', 'Media and Video', 'Medical', 'Photography', 'Casual', 'Cards and Casino', 'Casual', 'News and Magazines', 'Books and Reference', 'Transportation', 'Media and Video', 'Business', 'Health and Fitness', 'Arcade and Action', 'Business', 'Finance', 'Brain and Puzzle', 'News and Magazines', 'Productivity', 'Photography', 'Health and Fitness', 'Weather', 'Casual', 'Finance', 'Media and Video', 'Music and Audio', 'Medical', 'Arcade and Action', 'Social', 'Libraries and Demo', 'Business', 'Transportation', 'Arcade and Action', 'Sports', 'Casual', 'Transportation', 'Transportation', 'Productivity', 'Arcade and Action', 'Casual', 'Entertainment', 'Arcade and Action', 'Comics', 'Personalization', 'Brain and Puzzle', 'Tools', 'Books and Reference', 'Lifestyle', 'Libraries and Demo', 'Communication', 'Sports', 'Weather', 'Shopping', 'Personalization', 'Communication', 'Finance', 'Social', 'Shopping', 'Music and Audio', 'Cards and Casino', 'Music and Audio', 'Lifestyle', 'Racing', 'Social', 'Social', 'Entertainment', 'Finance', 'Libraries and Demo', 'Racing', 'Photography', 'News and Magazines', 'Weather', 'Cards and Casino', 'Social', 'Racing', 'Arcade and Action', 'Music and Audio', 'Weather', 'Finance', 'Personalization', 'Social', 'Finance', 'Finance', 'Communication', 'Sports Games', 'Arcade and Action', 'Transportation', 'Shopping', 'Education', 'Personalization', 'Finance', 'Transportation', 'Business', 'Personalization', 'Shopping', 'Finance', 'Productivity', 'Cards and Casino', 'Music and Audio', 'Shopping', 'Entertainment', 'Personalization', 'Tools', 'Transportation', 'Casual', 'Arcade and Action', 'Sports', 'Media and Video', 'Transportation', 'Communication', 'Communication', 'Transportation', 'Entertainment', 'Education', 'Health and Fitness', 'Tools', 'Tools', 'Productivity', 'Personalization', 'News and Magazines', 'Books and Reference', 'Racing', 'Shopping', 'Photography', 'Racing', 'Casual', 'Lifestyle', 'Photography', 'Finance', 'Entertainment', 'Photography', 'Casual', 'Communication', 'Books and Reference', 'Health and Fitness', 'Libraries and Demo', 'Arcade and Action', 'Music and Audio', 'Education', 'Productivity', 'Business', 'Finance', 'Cards and Casino', 'Shopping', 'Travel and Local', 'Casual', 'Entertainment', 'Racing', 'Racing', 'Transportation', 'Shopping', 'Shopping', 'Photography', 'Shopping', 'Casual', 'Libraries and Demo', 'Education', 'Racing', 'Personalization', 'Arcade and Action', 'Music and Audio', 'Cards and Casino', 'Transportation', 'Health and Fitness', 'Finance', 'Education', 'Shopping', 'Sports', 'Personalization', 'Tools', 'Medical', 'Media and Video', 'Libraries and Demo', 'Finance', 'Communication', 'Weather', 'Cards and Casino', 'Media and Video', 'Communication', 'Photography', 'Business', 'Arcade and Action', 'Brain and Puzzle', 'Sports', 'Travel and Local', 'Arcade and Action', 'Arcade and Action', 'Lifestyle', 'Photography', 'Photography', 'Travel and Local', 'Casual', 'Brain and Puzzle', 'Business', 'Travel and Local', 'Education', 'Entertainment', 'Casual', 'Social', 'Music and Audio', 'Racing', 'Photography', 'Photography', 'Finance', 'Brain and Puzzle', 'Cards and Casino', 'Personalization', 'Comics', 'Transportation', 'Health and Fitness', 'Arcade and Action', 'Racing', 'Lifestyle', 'Libraries and Demo', 'Travel and Local', 'Entertainment', 'News and Magazines', 'Health and Fitness', 'Communication', 'Brain and Puzzle', 'Social', 'Personalization', 'Photography', 'News and Magazines', 'Music and Audio', 'Photography', 'Music and Audio', 'Music and Audio', 'Communication', 'Books and Reference', 'Tools', 'Shopping', 'Education', 'Business', 'Finance', 'Social', 'Photography', 'Media and Video', 'Photography', 'Education', 'Photography', 'Libraries and Demo', 'Productivity', 'News and Magazines', 'Sports', 'Lifestyle', 'Lifestyle', 'Communication', 'Lifestyle', 'Arcade and Action', 'Casual', 'Entertainment', 'Music and Audio', 'Casual', 'Media and Video', 'News and Magazines', 'Racing', 'Books and Reference', 'Weather', 'Medical', 'Photography', 'Casual', 'Health and Fitness', 'Cards and Casino', 'Comics', 'Cards and Casino', 'Brain and Puzzle', 'Lifestyle', 'Photography', 'Health and Fitness', 'Sports', 'Business', 'Shopping', 'Shopping', 'Arcade and Action', 'Productivity', 'Tools', 'Arcade and Action', 'Music and Audio', 'Casual', 'Transportation', 'Music and Audio', 'Books and Reference', 'Health and Fitness', 'Personalization', 'Communication', 'Entertainment', 'Cards and Casino', 'Racing', 'Finance', 'Communication', 'Weather', 'Racing', 'Books and Reference', 'Social', 'Productivity', 'Health and Fitness', 'Books and Reference', 'Media and Video', 'Health and Fitness', 'Sports Games', 'Comics', 'Entertainment', 'Education', 'Personalization', 'Media and Video', 'Lifestyle', 'Media and Video', 'Personalization', 'Sports', 'Shopping', 'Travel and Local', 'Personalization', 'News and Magazines', 'Travel and Local', 'Arcade and Action', 'Personalization', 'News and Magazines', 'News and Magazines', 'Productivity', 'Arcade and Action', 'Music and Audio', 'Personalization', 'Communication', 'Cards and Casino', 'Cards and Casino', 'Health and Fitness', 'Racing', 'Transportation', 'Education', 'Comics', 'News and Magazines', 'Tools', 'Music and Audio', 'News and Magazines', 'Communication', 'Communication', 'Entertainment', 'Tools', 'Racing', 'Libraries and Demo', 'Casual', 'Casual', 'Media and Video', 'Photography', 'Personalization', 'Education', 'Sports', 'Business', 'Business', 'Cards and Casino', 'Finance', 'Weather', 'Communication', 'Photography', 'Music and Audio', 'Personalization', 'Medical', 'Brain and Puzzle', 'Books and Reference', 'Education', 'News and Magazines', 'Casual', 'Entertainment', 'Photography', 'Medical', 'Casual', 'Photography', 'Sports', 'Weather', 'Media and Video', 'Tools', 'Personalization', 'Communication', 'Travel and Local', 'Education', 'Tools', 'Personalization', 'Cards and Casino', 'Arcade and Action', 'Arcade and Action', 'Music and Audio', 'Personalization', 'Education', 'Communication', 'Music and Audio', 'Finance', 'Brain and Puzzle', 'Finance', 'Communication', 'Weather', 'Shopping', 'Communication', 'Music and Audio', 'Finance', 'Business', 'Music and Audio', 'Racing', 'Travel and Local', 'Education', 'Travel and Local', 'Arcade and Action', 'Social', 'Finance', 'Casual', 'Business', 'Shopping', 'Racing', 'Transportation', 'Arcade and Action', 'Health and Fitness', 'Tools', 'Personalization', 'Transportation', 'Tools', 'Photography', 'Sports Games', 'News and Magazines', 'Media and Video', 'Productivity', 'Shopping', 'Books and Reference', 'Lifestyle', 'Medical', 'Personalization', 'Weather', 'Productivity', 'Arcade and Action', 'Photography', 'News and Magazines', 'Medical', 'Education', 'Entertainment', 'Racing', 'Books and Reference', 'Racing', 'Productivity', 'Travel and Local', 'Arcade and Action', 'Music and Audio', 'Racing', 'Photography', 'Tools', 'Lifestyle', 'Cards and Casino', 'Tools', 'Lifestyle', 'Health and Fitness', 'Photography', 'Cards and Casino', 'Shopping', 'Communication', 'Libraries and Demo', 'Racing', 'Cards and Casino', 'Cards and Casino', 'Libraries and Demo', 'Health and Fitness', 'Casual', 'Education', 'Books and Reference', 'Brain and Puzzle', 'Travel and Local', 'Arcade and Action', 'Media and Video', 'Brain and Puzzle', 'Personalization', 'Brain and Puzzle', 'Personalization', 'Sports Games', 'Personalization', 'Business', 'Music and Audio', 'Books and Reference', 'Transportation', 'Arcade and Action', 'Business', 'Transportation', 'Finance', 'Media and Video', 'Entertainment', 'Racing', 'Business', 'Racing', 'Books and Reference', 'Media and Video', 'Books and Reference', 'Communication', 'Music and Audio', 'Education', 'Finance', 'Shopping', 'Business', 'Travel and Local', 'Tools', 'Cards and Casino', 'Books and Reference', 'Communication', 'Casual', 'Medical', 'Media and Video', 'Libraries and Demo', 'Shopping', 'Communication', 'Entertainment', 'Casual', 'Media and Video', 'Health and Fitness', 'Productivity', 'News and Magazines', 'Photography', 'Weather', 'Education', 'Shopping', 'Shopping', 'Transportation', 'Productivity', 'Music and Audio', 'Social', 'Social', 'Tools', 'Tools', 'Business', 'Finance', 'Cards and Casino', 'Education', 'Tools', 'Music and Audio', 'Travel and Local', 'Business', 'Tools', 'Tools', 'Entertainment', 'Business', 'Business', 'Social', 'News and Magazines', 'Productivity', 'Travel and Local', 'Music and Audio', 'Sports Games', 'Photography', 'Business', 'Health and Fitness', 'Arcade and Action', 'Cards and Casino', 'Music and Audio', 'Travel and Local', 'Education', 'Transportation', 'Arcade and Action', 'Social', 'Education', 'Arcade and Action', 'Social', 'Tools', 'Books and Reference', 'Lifestyle', 'Photography', 'Productivity', 'Sports Games', 'Personalization', 'Brain and Puzzle', 'Entertainment', 'Productivity', 'Education', 'Arcade and Action', 'Sports Games', 'News and Magazines', 'Sports', 'Sports', 'Cards and Casino', 'Lifestyle', 'Personalization', 'Entertainment', 'Transportation', 'Communication', 'Books and Reference', 'Casual', 'Health and Fitness', 'Photography', 'Weather', 'Media and Video', 'Books and Reference', 'Entertainment', 'Shopping', 'Photography', 'Sports Games', 'Communication', 'Sports', 'Education', 'Cards and Casino', 'Personalization', 'Lifestyle', 'Communication', 'Brain and Puzzle', 'Cards and Casino', 'Health and Fitness', 'Communication', 'Entertainment', 'Sports', 'Travel and Local', 'Casual', 'Photography', 'Cards and Casino', 'Lifestyle', 'Entertainment', 'Personalization', 'News and Magazines', 'Weather', 'News and Magazines', 'Education', 'News and Magazines', 'Health and Fitness', 'Weather', 'Productivity', 'Media and Video', 'Transportation', 'Casual', 'Media and Video', 'Casual', 'Health and Fitness', 'Education', 'Transportation', 'Sports', 'Casual', 'Media and Video', 'Personalization', 'News and Magazines', 'Finance', 'Medical', 'Photography', 'Casual', 'Casual', 'News and Magazines', 'Music and Audio', 'Lifestyle', 'Cards and Casino', 'Tools', 'Medical', 'Racing', 'Travel and Local', 'Shopping', 'Cards and Casino', 'Communication', 'Education', 'Travel and Local', 'Personalization', 'Education', 'Travel and Local', 'Health and Fitness', 'Tools', 'Education', 'Music and Audio', 'Transportation', 'Sports', 'Shopping', 'News and Magazines', 'Business', 'Business', 'Comics', 'Lifestyle', 'Books and Reference', 'Education', 'Libraries and Demo', 'Music and Audio', 'Cards and Casino', 'News and Magazines', 'Cards and Casino', 'Media and Video', 'Social', 'Weather', 'Lifestyle', 'Productivity', 'Casual', 'Brain and Puzzle', 'Education', 'Casual', 'Brain and Puzzle', 'Shopping', 'Cards and Casino', 'Libraries and Demo', 'Shopping', 'Social', 'Cards and Casino', 'Media and Video', 'Personalization', 'Photography', 'Arcade and Action', 'Medical', 'Sports', 'Entertainment', 'Medical', 'Tools', 'Health and Fitness', 'Tools', 'Business', 'Cards and Casino', 'Media and Video', 'Finance', 'Business', 'Sports Games', 'Medical', 'Books and Reference', 'Racing', 'Media and Video', 'Health and Fitness', 'Transportation', 'Sports', 'Personalization', 'Health and Fitness', 'Travel and Local', 'Transportation', 'Finance', 'Personalization', 'Productivity', 'Entertainment', 'Travel and Local', 'Sports Games', 'Business', 'Weather', 'Tools', 'Health and Fitness', 'Medical', 'Tools', 'Racing', 'News and Magazines', 'Music and Audio', 'Brain and Puzzle', 'Racing', 'Cards and Casino', 'Education', 'Finance', 'Productivity', 'Medical', 'Health and Fitness', 'Photography', 'Books and Reference', 'Communication', 'Health and Fitness', 'Medical', 'Libraries and Demo', 'Health and Fitness', 'Casual', 'News and Magazines', 'Arcade and Action', 'Arcade and Action', 'Brain and Puzzle', 'Social', 'Cards and Casino', 'Entertainment', 'Cards and Casino', 'Sports', 'Travel and Local', 'Health and Fitness', 'Sports', 'Lifestyle', 'Books and Reference', 'News and Magazines', 'Weather', 'Health and Fitness', 'Tools', 'Brain and Puzzle', 'Music and Audio', 'Photography', 'News and Magazines', 'Lifestyle', 'Entertainment', 'Racing', 'Sports Games', 'Transportation', 'News and Magazines', 'Sports', 'Libraries and Demo', 'News and Magazines', 'Media and Video', 'Social', 'Communication', 'Brain and Puzzle', 'Arcade and Action', 'Communication', 'Business', 'Education', 'Brain and Puzzle', 'Music and Audio', 'Weather', 'Health and Fitness', 'Medical', 'Entertainment', 'Casual', 'Sports', 'Finance', 'Brain and Puzzle', 'Books and Reference', 'Health and Fitness', 'Arcade and Action', 'Business', 'Brain and Puzzle', 'Travel and Local', 'Tools', 'Transportation', 'Entertainment', 'Health and Fitness', 'Arcade and Action', 'Brain and Puzzle', 'Arcade and Action', 'Arcade and Action', 'Lifestyle', 'Comics', 'Books and Reference', 'Travel and Local', 'Arcade and Action', 'Shopping', 'News and Magazines', 'Personalization', 'Casual', 'Brain and Puzzle', 'Arcade and Action', 'Shopping', 'Medical', 'Social', 'Brain and Puzzle', 'Productivity', 'Media and Video', 'Cards and Casino', 'Shopping', 'Arcade and Action', 'Tools', 'Casual', 'Transportation', 'Media and Video', 'Business', 'Libraries and Demo', 'Arcade and Action', 'Finance', 'Lifestyle', 'Social', 'Music and Audio', 'Education', 'Finance', 'Cards and Casino', 'Transportation', 'Libraries and Demo', 'Social', 'Transportation', 'Education', 'Casual', 'Sports', 'Weather', 'Cards and Casino', 'Brain and Puzzle', 'Productivity', 'Lifestyle', 'Arcade and Action', 'Health and Fitness', 'Tools', 'Sports', 'Finance', 'Health and Fitness', 'Personalization', 'Books and Reference', 'Social', 'Business', 'Health and Fitness', 'Cards and Casino', 'Photography', 'Entertainment', 'Casual', 'Tools', 'Business', 'Media and Video', 'Tools', 'Libraries and Demo', 'Social', 'Cards and Casino', 'Shopping', 'Personalization', 'Weather', 'News and Magazines', 'Music and Audio', 'Transportation', 'Racing', 'Business', 'Sports Games', 'Education', 'Health and Fitness', 'Finance', 'Communication', 'Entertainment', 'Racing', 'Sports', 'Sports', 'Lifestyle', 'Photography', 'Music and Audio', 'Education', 'Finance', 'Brain and Puzzle', 'Media and Video', 'Tools', 'Productivity', 'Racing', 'Social', 'News and Magazines', 'Travel and Local', 'Personalization', 'Finance', 'Sports', 'Transportation', 'Lifestyle', 'Casual', 'Weather', 'Books and Reference', 'Cards and Casino', 'Finance', 'Productivity', 'Libraries and Demo', 'Casual', 'Photography', 'Social', 'Transportation', 'Photography', 'News and Magazines', 'Shopping', 'Weather', 'Media and Video', 'Books and Reference', 'Arcade and Action', 'Business', 'Sports Games', 'Personalization', 'Sports', 'Music and Audio', 'Photography', 'Communication', 'Social', 'Finance', 'Social', 'Education', 'Music and Audio', 'Casual', 'Education', 'Music and Audio', 'Medical', 'Education', 'Photography', 'Comics', 'Arcade and Action', 'Medical', 'Entertainment', 'Books and Reference', 'Social', 'Health and Fitness', 'Business', 'Tools', 'Travel and Local', 'Media and Video', 'Photography', 'Lifestyle', 'Tools', 'News and Magazines', 'Communication', 'Transportation', 'Photography', 'Entertainment', 'Productivity', 'Tools', 'Cards and Casino', 'Brain and Puzzle', 'Cards and Casino', 'Medical', 'Social', 'Transportation', 'Music and Audio', 'Music and Audio', 'Tools', 'Shopping', 'Personalization', 'Arcade and Action', 'Libraries and Demo', 'Lifestyle', 'Brain and Puzzle', 'Arcade and Action', 'Education', 'Comics', 'Sports Games', 'Medical', 'Social', 'Communication', 'Arcade and Action', 'Business', 'Arcade and Action', 'Business', 'Communication', 'Arcade and Action', 'Arcade and Action', 'Health and Fitness', 'Social', 'News and Magazines', 'Media and Video', 'Tools', 'Music and Audio', 'Medical', 'Finance', 'Business', 'Medical', 'Tools', 'Tools', 'Weather', 'Books and Reference', 'Social', 'Casual', 'Media and Video', 'Libraries and Demo', 'Health and Fitness', 'Communication', 'News and Magazines', 'Sports', 'Health and Fitness', 'Travel and Local', 'News and Magazines', 'Health and Fitness', 'Personalization', 'Racing', 'Entertainment', 'Music and Audio', 'Tools', 'Travel and Local', 'Entertainment', 'Sports', 'Tools', 'Finance', 'Brain and Puzzle', 'Libraries and Demo', 'Tools', 'Sports Games', 'Music and Audio', 'Communication', 'Tools', 'Brain and Puzzle', 'Education', 'Education', 'Sports', 'Entertainment', 'Arcade and Action', 'Shopping', 'Lifestyle', 'Arcade and Action', 'Weather', 'Photography', 'Entertainment', 'Books and Reference', 'Casual', 'Lifestyle', 'Racing', 'Music and Audio', 'Lifestyle', 'Cards and Casino', 'Tools', 'Books and Reference', 'Education', 'Comics', 'Business', 'Travel and Local', 'Tools', 'Libraries and Demo', 'Music and Audio', 'Music and Audio', 'Libraries and Demo', 'Productivity', 'Lifestyle', 'Media and Video', 'Social', 'Transportation', 'Lifestyle', 'Business', 'Casual', 'Travel and Local', 'Casual', 'Tools', 'News and Magazines', 'Personalization', 'Racing', 'Communication', 'Travel and Local', 'Brain and Puzzle', 'Books and Reference', 'Casual', 'News and Magazines', 'News and Magazines', 'Cards and Casino', 'Shopping', 'Music and Audio', 'Transportation', 'Arcade and Action', 'Sports', 'Medical', 'Productivity', 'Personalization', 'Music and Audio', 'Personalization', 'News and Magazines', 'Travel and Local', 'Finance', 'Social', 'Cards and Casino', 'Personalization', 'Tools', 'Media and Video', 'Business', 'Weather', 'Tools', 'Productivity', 'Finance', 'Casual', 'Shopping', 'Music and Audio', 'Education', 'Tools', 'Entertainment', 'Shopping', 'Photography', 'Health and Fitness', 'Photography', 'Photography', 'Cards and Casino', 'Books and Reference', 'Books and Reference', 'Communication', 'Health and Fitness', 'Entertainment', 'Transportation', 'Social', 'Weather', 'Cards and Casino', 'Music and Audio', 'Social', 'Business', 'Sports', 'Brain and Puzzle', 'Books and Reference', 'Media and Video', 'Casual', 'Personalization', 'Media and Video', 'Weather', 'Shopping', 'Finance', 'Brain and Puzzle', 'Arcade and Action', 'Music and Audio', 'Social', 'Business', 'Medical', 'Photography', 'Books and Reference', 'Health and Fitness', 'Productivity', 'Music and Audio', 'Comics', 'Personalization', 'Shopping', 'Sports', 'Entertainment', 'Photography', 'Casual', 'Casual', 'Shopping', 'Cards and Casino', 'Lifestyle', 'Shopping', 'Travel and Local', 'Books and Reference', 'Arcade and Action', 'Lifestyle', 'News and Magazines', 'Libraries and Demo', 'Music and Audio', 'Sports', 'Health and Fitness', 'Weather', 'Cards and Casino', 'Medical', 'Cards and Casino', 'Personalization', 'Personalization', 'Books and Reference', 'Weather', 'Cards and Casino', 'Business', 'Social', 'Sports', 'Brain and Puzzle', 'Travel and Local', 'News and Magazines', 'Photography', 'Social', 'Travel and Local', 'Racing', 'Education', 'Finance', 'Books and Reference', 'Books and Reference', 'Books and Reference', 'Sports', 'Transportation', 'Entertainment', 'Casual', 'Sports', 'Shopping', 'Music and Audio', 'Casual', 'Books and Reference', 'Communication', 'Libraries and Demo', 'Medical', 'Productivity', 'News and Magazines', 'Cards and Casino', 'Lifestyle', 'Arcade and Action', 'Entertainment', 'Sports', 'Social', 'Weather', 'Brain and Puzzle', 'Libraries and Demo', 'Brain and Puzzle', 'Photography', 'Music and Audio', 'Productivity', 'Transportation', 'Photography', 'Sports Games', 'Racing', 'Entertainment', 'Transportation', 'Social', 'Business', 'Communication', 'Casual', 'Business', 'Shopping', 'Entertainment', 'Travel and Local', 'Communication', 'Libraries and Demo', 'Books and Reference', 'Shopping', 'Sports', 'Cards and Casino', 'Medical', 'News and Magazines', 'Photography', 'Tools', 'Photography', 'Shopping', 'News and Magazines', 'Tools', 'Music and Audio', 'Health and Fitness', 'Books and Reference', 'News and Magazines', 'Lifestyle', 'Health and Fitness', 'Racing', 'Racing', 'Cards and Casino', 'Health and Fitness', 'News and Magazines', 'Entertainment', 'Tools', 'Casual', 'Media and Video', 'Media and Video', 'Weather', 'Weather', 'Communication', 'Social', 'Media and Video', 'Business', 'Arcade and Action', 'Racing', 'Social', 'Personalization', 'Tools', 'Social', 'Cards and Casino', 'News and Magazines', 'Business', 'Weather', 'Shopping', 'Racing', 'Personalization', 'Personalization', 'News and Magazines', 'Social', 'Sports', 'Personalization', 'Tools', 'Arcade and Action', 'Entertainment', 'Music and Audio', 'Education', 'Personalization', 'Finance', 'Casual', 'Communication', 'Books and Reference', 'Tools', 'Communication', 'Lifestyle', 'Libraries and Demo', 'Media and Video', 'Travel and Local', 'Brain and Puzzle', 'Communication', 'Brain and Puzzle', 'Tools', 'Shopping', 'Cards and Casino', 'Libraries and Demo', 'Travel and Local', 'Communication', 'Books and Reference', 'Cards and Casino', 'Photography', 'Arcade and Action', 'Comics', 'News and Magazines', 'Finance', 'Tools', 'Sports', 'News and Magazines', 'Sports', 'Communication', 'Photography', 'News and Magazines', 'Casual', 'Racing', 'Travel and Local', 'News and Magazines', 'Arcade and Action', 'Communication', 'News and Magazines', 'Transportation', 'Entertainment', 'Sports Games', 'Comics', 'Music and Audio', 'Books and Reference', 'Communication', 'Finance', 'Media and Video', 'Photography', 'Communication', 'Transportation', 'Medical', 'Finance', 'Music and Audio', 'Medical', 'Media and Video', 'Brain and Puzzle', 'News and Magazines', 'Sports Games', 'Casual', 'Education', 'Health and Fitness', 'Medical', 'Sports', 'Education', 'Personalization', 'Weather', 'Entertainment', 'Social', 'Books and Reference', 'Travel and Local', 'Arcade and Action', 'Music and Audio', 'Lifestyle', 'Photography', 'Communication', 'Tools', 'Casual', 'Social', 'Travel and Local', 'Entertainment', 'Education', 'Productivity', 'Libraries and Demo', 'Productivity', 'Photography', 'Communication', 'Health and Fitness', 'Photography', 'Comics', 'Business', 'Education', 'Cards and Casino', 'Education', 'Lifestyle', 'Productivity', 'Business', 'Lifestyle', 'Libraries and Demo', 'Health and Fitness', 'Social', 'Productivity', 'Casual', 'Photography', 'Entertainment', 'Entertainment', 'News and Magazines', 'Transportation', 'Media and Video', 'Lifestyle', 'Brain and Puzzle', 'Books and Reference', 'Education', 'News and Magazines', 'Books and Reference', 'Cards and Casino', 'Personalization', 'Communication', 'Arcade and Action', 'Photography', 'Libraries and Demo', 'Social', 'Photography', 'Communication', 'Tools', 'Tools', 'Travel and Local', 'Health and Fitness', 'Productivity', 'Transportation', 'Personalization', 'Libraries and Demo', 'Tools', 'Media and Video', 'Media and Video', 'Entertainment', 'Casual', 'Comics', 'Racing', 'Sports', 'Brain and Puzzle', 'Photography', 'Comics', 'Books and Reference', 'Business', 'Social', 'News and Magazines', 'Libraries and Demo', 'Music and Audio', 'Weather', 'Productivity', 'Arcade and Action', 'Music and Audio', 'Finance', 'Transportation', 'Productivity', 'Health and Fitness', 'Photography', 'Tools', 'Entertainment', 'Cards and Casino', 'Lifestyle', 'Personalization', 'Finance', 'Communication', 'Music and Audio', 'Arcade and Action', 'Lifestyle', 'Photography', 'Social', 'Racing', 'Communication', 'Cards and Casino', 'Health and Fitness', 'Business', 'Media and Video', 'Books and Reference', 'Medical', 'Tools', 'Finance', 'Transportation', 'Entertainment', 'Sports', 'Social', 'Education', 'Sports', 'Medical', 'Transportation', 'Communication', 'Education', 'Productivity', 'Personalization', 'Brain and Puzzle', 'Brain and Puzzle', 'Productivity', 'Media and Video', 'Music and Audio', 'Transportation', 'Education', 'Education', 'Casual', 'Brain and Puzzle', 'Brain and Puzzle', 'Education', 'News and Magazines', 'Health and Fitness', 'Transportation', 'Weather', 'Health and Fitness', 'Photography', 'Arcade and Action', 'Tools', 'Sports Games', 'Business', 'Cards and Casino', 'Entertainment', 'Medical', 'Finance', 'Business', 'Social', 'Business', 'Entertainment', 'Music and Audio', 'Finance', 'Music and Audio', 'Casual', 'Media and Video', 'Brain and Puzzle', 'Shopping', 'Arcade and Action', 'Business', 'Communication', 'Travel and Local', 'Productivity', 'Cards and Casino', 'Finance', 'Communication', 'Brain and Puzzle', 'Lifestyle', 'Casual', 'Medical', 'Arcade and Action', 'Finance', 'Brain and Puzzle', 'Media and Video', 'News and Magazines', 'Entertainment', 'Entertainment', 'Libraries and Demo', 'Tools', 'Social', 'Books and Reference', 'Tools', 'Weather', 'Productivity', 'Transportation', 'Communication', 'Sports Games', 'Education', 'Transportation', 'Health and Fitness', 'Brain and Puzzle', 'Shopping', 'Cards and Casino', 'Entertainment', 'Communication', 'Education', 'Music and Audio', 'Arcade and Action', 'Tools', 'Lifestyle', 'Transportation', 'Media and Video', 'Personalization', 'Personalization', 'Photography', 'Education', 'Travel and Local', 'Books and Reference', 'Personalization', 'Social', 'Cards and Casino', 'Communication', 'Arcade and Action', 'Arcade and Action', 'Casual', 'Casual', 'Personalization', 'Arcade and Action', 'Media and Video', 'Shopping', 'Personalization', 'Photography', 'News and Magazines', 'Books and Reference', 'Tools', 'Media and Video', 'Transportation', 'Sports', 'Shopping', 'Communication', 'Libraries and Demo', 'Shopping', 'Education', 'Personalization', 'Personalization', 'Music and Audio', 'Business', 'Medical', 'Transportation', 'Photography', 'Social', 'Health and Fitness', 'Arcade and Action', 'Media and Video', 'Arcade and Action', 'Music and Audio', 'Tools', 'Tools', 'Travel and Local', 'Productivity', 'Lifestyle', 'News and Magazines', 'Racing', 'Entertainment', 'Entertainment', 'Books and Reference', 'Books and Reference', 'News and Magazines', 'Business', 'Education', 'Books and Reference', 'Entertainment', 'Sports', 'Weather', 'Brain and Puzzle', 'Weather', 'Music and Audio', 'Books and Reference', 'Music and Audio', 'Entertainment', 'Education', 'Casual', 'Personalization', 'Education', 'Education', 'Cards and Casino', 'Cards and Casino', 'News and Magazines', 'Sports Games', 'Comics', 'Medical', 'Cards and Casino', 'Weather', 'Racing', 'Media and Video', 'Business', 'Tools', 'Books and Reference', 'Music and Audio', 'Libraries and Demo', 'Lifestyle', 'Education', 'Racing', 'Libraries and Demo', 'Books and Reference', 'Education', 'Sports Games', 'Racing', 'Health and Fitness', 'Medical', 'Music and Audio', 'Casual', 'Music and Audio', 'Health and Fitness', 'Books and Reference', 'Racing', 'Finance', 'Weather', 'Travel and Local', 'Finance', 'Libraries and Demo', 'Arcade and Action', 'Books and Reference', 'Personalization', 'Entertainment', 'Sports Games', 'Medical', 'Photography', 'Arcade and Action', 'Photography', 'Productivity', 'Business', 'Music and Audio', 'Casual', 'Transportation', 'Media and Video', 'Libraries and Demo', 'Weather', 'Communication', 'Sports', 'Shopping', 'Communication', 'Lifestyle', 'Health and Fitness', 'Education', 'Productivity', 'Productivity', 'Social', 'Comics', 'Social', 'Entertainment', 'Arcade and Action', 'Comics', 'Shopping', 'Medical', 'Productivity', 'Music and Audio', 'Casual', 'Sports', 'Brain and Puzzle', 'Travel and Local', 'Lifestyle', 'Business', 'Libraries and Demo', 'Entertainment', 'Health and Fitness', 'Weather', 'Transportation', 'Travel and Local', 'Communication', 'Personalization', 'Entertainment', 'Brain and Puzzle', 'Sports', 'Photography', 'Racing', 'Books and Reference', 'Music and Audio', 'Education', 'Photography', 'Personalization', 'Communication', 'Lifestyle', 'Medical', 'Brain and Puzzle', 'Medical', 'Books and Reference', 'Transportation', 'Racing', 'Entertainment', 'Weather', 'Shopping', 'Weather', 'Health and Fitness', 'Brain and Puzzle', 'Health and Fitness', 'Travel and Local', 'Travel and Local', 'Books and Reference', 'Media and Video', 'Health and Fitness']\n"
     ]
    }
   ],
   "source": [
    "testpred\n",
    "testpredlabels = []\n",
    "for i in testpred:\n",
    "  testpredlabels.append(labels[i])\n",
    "  \n",
    "print(testpredlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "-CV28gyFY_n4",
    "outputId": "6c701818-88d6-4052-ed7a-d2708ca070d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      0                    0\n",
      "0  dalmax.games.turnBasedGames.connect4     Brain and Puzzle\n",
      "1          com.holfeld.japaneseplusfree     Travel and Local\n",
      "2              com.mobileApp.controller         Productivity\n",
      "3      com.aarontennyson.calorietracker   Health and Fitness\n",
      "4  com.totaldevel.android.todocitas.ads  Books and Reference\n"
     ]
    }
   ],
   "source": [
    "#output test data prediction\n",
    "submissionfile = pd.read_csv('test_data.csv', header = None)[0]\n",
    "submissionfile = pd.concat([submissionfile, pd.Series(testpredlabels)], axis = 1)\n",
    "print(submissionfile.head())\n",
    "submissionfile.to_csv('predicted_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "uMoZHbbmNRnG",
    "outputId": "39021a7f-8e6b-4ff1-8faf-8aad78568ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      0                    0\n",
      "0  dalmax.games.turnBasedGames.connect4     Brain and Puzzle\n",
      "1          com.holfeld.japaneseplusfree     Travel and Local\n",
      "2              com.mobileApp.controller         Productivity\n",
      "3      com.aarontennyson.calorietracker   Health and Fitness\n",
      "4  com.totaldevel.android.todocitas.ads  Books and Reference\n",
      "Uploaded file with ID 1kAjvNj-cfJEveRGppoyuLUigMddClZnx\n"
     ]
    }
   ],
   "source": [
    "#del test\n",
    "submissionfile = pd.read_csv('test_data.csv', header = None)[0]\n",
    "submissionfile = pd.concat([submissionfile, pd.Series(testpredlabels)], axis = 1)\n",
    "print(submissionfile.head())\n",
    "\n",
    "submissionfile.to_csv('predicted_labels.csv', index = False)\n",
    "\n",
    "export_csv = submissionfile.to_csv('predicted_labels.csv')\n",
    "\n",
    "uploaded = drive.CreateFile({'title': 'predicted_labels.csv'})\n",
    "uploaded.SetContentFile('predicted_labels.csv')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXwLgIecsBBK"
   },
   "source": [
    "The experiment result shows that logistic regression gives higher accuracy than naive bayes in general. One of the possible reasons why logistic regression is outperforming naive bayes is that logistic regression assumes a linear relationship between all dependent and independent variables. This assumption preserves the relative influence between different words while naive bayes ignore it by assumping the occurences of words are independent events. \n",
    "\n",
    "Another pattern we can see from our experiment result is that ensemble model outperforms individual classifier in general. This further proves our research findings that ensemble model usually gives higher accuracy and lower variance on the prediction results. The stronger classifier within the ensemble model can usually drag up the result of the weaker classifier, and thus achieves better model. And in the bagging case, the permutation of the training data can potentially generate new information for the classifier to learn. However, it is not alway the case that ensemble will perform better. In the ensemble model with both naive bayes classfiers and logistic regression classifers, the naive bayes classfier drag down the performance of logistic regression. Thus, it is also important to choose the best base models before building an emsemble.\n",
    "\n",
    "Results for both the 'Lifestyle' and 'Entertainment' labels were bad for both models, with F-scores lower than 0.35. Moreover, both models had very low recall values for the 'Lifestyle' label, suggesting that the label was rarely selected. The consistency between both models in predicting the 'Lifestyle' and 'Entertainment' categories suggests that the class itself is difficult to classify using a bag of words representation. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tB9UVjbwtCRW"
   },
   "source": [
    "list of references\n",
    "\n",
    "1. Dietterich, T. G. (2000, June). Ensemble methods in machine learning. In International workshop on multiple classifier systems (pp. 1-15). Springer, Berlin, Heidelberg.\n",
    "2. Lewis, D. D. (1998, April). Naive (Bayes) at forty: The independence assumption in information retrieval. In European conference on machine learning (pp. 4-15). Springer, Berlin, Heidelberg.  \n",
    "3. Martin, J. H., & Jurafsky, D. (2009). Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition. Pearson/Prentice Hall.\n",
    "4. Opitz, D., & Maclin, R. (1999). Popular ensemble methods: An empirical study. Journal of artificial intelligence research, 11, 169-198.\n",
    "5. Rennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003). Tackling the poor assumptions of naive bayes text classifiers. In Proceedings of the 20th international conference on machine learning (ICML-03) (pp. 616-623).\n",
    "6. Russell, S. J., & Norvig, P. (2016). Artificial intelligence: a modern approach. Malaysia; Pearson Education Limited,.\n",
    "7. Schütze, H., Manning, C. D., & Raghavan, P. (2008). Introduction to information retrieval (Vol. 39). Cambridge University Press.\n",
    "8. Smolyakov, V. (2017). Ensemble Learning to Improve Machine Learning Results. Retrieved from: https://blog.statsbot.co/ensemble-learning-d1dcd548e936 \n",
    "9. Vryniotis , V. (2013). Machine Learning Tutorial: The Multinomial Logistic Regression (Softmax Regression). Retrieved from: http://blog.datumbox.com/machine-learning-tutorial-the-multinomial-logistic-regression-softmax-regression/\n",
    "10. Winston, P. (2010). Learning: Boosting [Video file]. Retrieved from: https://www.youtube.com/watch?v=UHBmv7qCey4#t=48m38s "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1_soto7322_yfen3515_jche6589.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
